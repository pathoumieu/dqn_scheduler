{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "X, y = digits.data[:-1], digits.target[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[1]\n",
    "num_classes = np.unique(y).shape[0]\n",
    "lr = 0.1\n",
    "\n",
    "y = pd.get_dummies(y).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define simple network and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_dim, num_classes, lr):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(lr=lr),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    return loss_history.lr[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    \n",
    "    def __init__(self, verbose):\n",
    "        self.verbose = verbose\n",
    "        self.losses = [np.inf]\n",
    "        self.acc = [0.0]\n",
    "        self.lr = [0.1]\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.lr.append(scheduler(len(self.losses)))\n",
    "        if epoch % 2 == 0:\n",
    "            print('learning rate: {}'.format(np.round(self.lr[-1], 4)))\n",
    "        \n",
    "#        if epoch % self.verbose == 0:\n",
    "#            # you can access loss, accuracy in self.params['metrics']\n",
    "#            print('{} - loss: {} - acc: {}\\n'.format(epoch, self.losses[-1], self.acc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.1\n",
      "learning rate: 0.1\n",
      "learning rate: 0.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-6eb46718e7ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                    verbose=0)\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3251\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3253\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3254\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3255\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    871\u001b[0m   \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m       \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model(input_dim, num_classes, lr)\n",
    "\n",
    "loss_history = LossHistory(verbose=10)\n",
    "lrate = LearningRateScheduler(scheduler)\n",
    "callbacks_list = [loss_history, lrate]\n",
    "history = model.fit(X, y, \n",
    "                   epochs=10000, \n",
    "                   batch_size=64, \n",
    "                   callbacks=callbacks_list, \n",
    "                   verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQNAgent():\n",
    "    \n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma *\n",
    "                          np.amax(self.model.predict(next_state)[0]))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00966972,  0.01622245,  0.0247398 , -0.00710952])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset():\n",
    "    model = get_model(input_dim, num_classes, lr)\n",
    "\n",
    "    loss_history = LossHistory(verbose=10)\n",
    "    lrate = LearningRateScheduler(scheduler)\n",
    "    \n",
    "    return model, loss_history, lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[inf]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_history.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.099\n",
      "1796/1796 - 1s - loss: 2.0244 - acc: 0.5423\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 3.7270 - acc: 0.4104\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 4.2895 - acc: 0.2567\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.9946 - acc: 0.6531\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 0.4437 - acc: 0.8402\n",
      "learning rate: 0.102\n",
      "1796/1796 - 0s - loss: 0.6082 - acc: 0.8157\n",
      "learning rate: 0.103\n",
      "1796/1796 - 0s - loss: 0.1542 - acc: 0.9504\n",
      "learning rate: 0.102\n",
      "1796/1796 - 0s - loss: 0.0911 - acc: 0.9710\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 0.0761 - acc: 0.9755\n",
      "learning rate: 0.102\n",
      "1796/1796 - 0s - loss: 0.0491 - acc: 0.9827\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 0.0349 - acc: 0.9900\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.2551 - acc: 0.9304\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 0.0386 - acc: 0.9900\n",
      "learning rate: 0.102\n",
      "1796/1796 - 0s - loss: 0.0233 - acc: 0.9928\n",
      "learning rate: 0.103\n",
      "1796/1796 - 0s - loss: 0.0252 - acc: 0.9939\n",
      "learning rate: 0.102\n",
      "1796/1796 - 0s - loss: 0.0182 - acc: 0.9944\n",
      "learning rate: 0.103\n",
      "1796/1796 - 0s - loss: 0.0117 - acc: 0.9983\n",
      "learning rate: 0.102\n",
      "1796/1796 - 0s - loss: 0.0088 - acc: 0.9978\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 0.0067 - acc: 0.9989\n",
      "learning rate: 0.102\n",
      "1796/1796 - 0s - loss: 0.0062 - acc: 0.9989\n",
      "episode: 0/100, score: 19, e: 1.0\n",
      "learning rate: 0.099\n",
      "1796/1796 - 1s - loss: nan - acc: 0.0980\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: nan - acc: 0.0991\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: nan - acc: 0.0991\n",
      "episode: 1/100, score: 2, e: 1.0\n",
      "learning rate: 0.099\n",
      "1796/1796 - 1s - loss: 5.1237 - acc: 0.2801\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: nan - acc: 0.1748\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: nan - acc: 0.0991\n",
      "learning rate: 0.102\n",
      "1796/1796 - 0s - loss: nan - acc: 0.0991\n",
      "episode: 2/100, score: 3, e: 1.0\n",
      "learning rate: 0.099\n",
      "1796/1796 - 1s - loss: 6.2160 - acc: 0.2339\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 1.8411 - acc: 0.3781\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 0.7454 - acc: 0.7522\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 0.5003 - acc: 0.8458\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 1.6652 - acc: 0.5646\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.6378 - acc: 0.7901\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 0.2248 - acc: 0.9265\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.1440 - acc: 0.9543\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 0.1906 - acc: 0.9454\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.2508 - acc: 0.9276\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 4.3518 - acc: 0.1281\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 2.3086 - acc: 0.0986\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 2.3061 - acc: 0.0997\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 2.3046 - acc: 0.0958\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 2.3043 - acc: 0.1013\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 2.3037 - acc: 0.0935\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 2.3037 - acc: 0.1008\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 2.3034 - acc: 0.1013\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 2.3033 - acc: 0.0947\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 2.3033 - acc: 0.0919\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 2.3034 - acc: 0.0913\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 2.3032 - acc: 0.0958\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 2.3034 - acc: 0.0986\n",
      "learning rate: 0.102\n",
      "1796/1796 - 0s - loss: 2.3034 - acc: 0.1008\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 2.3034 - acc: 0.1013\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 2.3032 - acc: 0.1013\n",
      "episode: 3/100, score: 25, e: 0.9\n",
      "learning rate: 0.101\n",
      "1796/1796 - 1s - loss: 3.4647 - acc: 0.3580\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.8552 - acc: 0.7283\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 0.3053 - acc: 0.9170\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 3.6749 - acc: 0.3825\n",
      "learning rate: 0.097\n",
      "1796/1796 - 0s - loss: 1.0940 - acc: 0.6720\n",
      "learning rate: 0.096\n",
      "1796/1796 - 0s - loss: 0.5497 - acc: 0.8363\n",
      "learning rate: 0.095\n",
      "1796/1796 - 0s - loss: 0.3565 - acc: 0.8948\n",
      "learning rate: 0.094\n",
      "1796/1796 - 0s - loss: nan - acc: 0.1097\n",
      "learning rate: 0.093\n",
      "1796/1796 - 0s - loss: nan - acc: 0.0991\n",
      "learning rate: 0.094\n",
      "1796/1796 - 0s - loss: nan - acc: 0.0991\n",
      "episode: 4/100, score: 9, e: 0.86\n",
      "learning rate: 0.099\n",
      "1796/1796 - 1s - loss: nan - acc: 0.0997\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: nan - acc: 0.0991\n",
      "learning rate: 0.097\n",
      "1796/1796 - 0s - loss: nan - acc: 0.0991\n",
      "episode: 5/100, score: 2, e: 0.86\n",
      "learning rate: 0.101\n",
      "1796/1796 - 1s - loss: 6.7059 - acc: 0.2055\n",
      "learning rate: 0.102\n",
      "1796/1796 - 0s - loss: 1.6507 - acc: 0.4465\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 1.0430 - acc: 0.6709\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.4444 - acc: 0.8680\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 0.5254 - acc: 0.8341\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.4509 - acc: 0.8937\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 0.3866 - acc: 0.8886\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.1711 - acc: 0.9482\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 0.2857 - acc: 0.9254\n",
      "learning rate: 0.102\n",
      "1796/1796 - 0s - loss: 0.1109 - acc: 0.9710\n",
      "learning rate: 0.103\n",
      "1796/1796 - 0s - loss: 0.6828 - acc: 0.8196\n",
      "learning rate: 0.104\n",
      "1796/1796 - 0s - loss: 7.9467 - acc: 0.3502\n",
      "learning rate: 0.105\n",
      "1796/1796 - 0s - loss: 1.0365 - acc: 0.6526\n",
      "learning rate: 0.106\n",
      "1796/1796 - 0s - loss: 2.0221 - acc: 0.3302\n",
      "learning rate: 0.105\n",
      "1796/1796 - 0s - loss: 1.2615 - acc: 0.5663\n",
      "learning rate: 0.104\n",
      "1796/1796 - 0s - loss: 0.9071 - acc: 0.6971\n",
      "learning rate: 0.103\n",
      "1796/1796 - 0s - loss: 0.3504 - acc: 0.8942\n",
      "learning rate: 0.104\n",
      "1796/1796 - 0s - loss: 1.1876 - acc: 0.6604\n",
      "learning rate: 0.103\n",
      "1796/1796 - 0s - loss: 2.7505 - acc: 0.3335\n",
      "learning rate: 0.104\n",
      "1796/1796 - 0s - loss: 1.1217 - acc: 0.5919\n",
      "learning rate: 0.105\n",
      "1796/1796 - 0s - loss: 1.1242 - acc: 0.6091\n",
      "learning rate: 0.104\n",
      "1796/1796 - 0s - loss: 0.7955 - acc: 0.7416\n",
      "learning rate: 0.103\n",
      "1796/1796 - 0s - loss: 0.5243 - acc: 0.8441\n",
      "learning rate: 0.104\n",
      "1796/1796 - 0s - loss: 0.4027 - acc: 0.8731\n",
      "learning rate: 0.105\n",
      "1796/1796 - 0s - loss: 0.3323 - acc: 0.9065\n",
      "learning rate: 0.104\n",
      "1796/1796 - 0s - loss: 5.8255 - acc: 0.4170\n",
      "learning rate: 0.103\n",
      "1796/1796 - 0s - loss: 1.1177 - acc: 0.5624\n",
      "learning rate: 0.104\n",
      "1796/1796 - 0s - loss: 0.9709 - acc: 0.6514\n",
      "learning rate: 0.105\n",
      "1796/1796 - 0s - loss: 0.6043 - acc: 0.8213\n",
      "learning rate: 0.104\n",
      "1796/1796 - 0s - loss: 0.3632 - acc: 0.8976\n",
      "learning rate: 0.103\n",
      "1796/1796 - 0s - loss: 0.2125 - acc: 0.9399\n",
      "learning rate: 0.104\n",
      "1796/1796 - 0s - loss: 0.6525 - acc: 0.8168\n",
      "learning rate: 0.105\n",
      "1796/1796 - 0s - loss: 1.0980 - acc: 0.6576\n",
      "learning rate: 0.106\n",
      "1796/1796 - 0s - loss: 2.6962 - acc: 0.2945\n",
      "learning rate: 0.105\n",
      "1796/1796 - 0s - loss: 1.4906 - acc: 0.4599\n",
      "learning rate: 0.106\n",
      "1796/1796 - 0s - loss: 0.7250 - acc: 0.7656\n",
      "learning rate: 0.105\n",
      "1796/1796 - 0s - loss: 0.4192 - acc: 0.8898\n",
      "learning rate: 0.104\n",
      "1796/1796 - 0s - loss: 0.1854 - acc: 0.9399\n",
      "learning rate: 0.103\n",
      "1796/1796 - 0s - loss: 0.1340 - acc: 0.9560\n",
      "learning rate: 0.104\n",
      "1796/1796 - 0s - loss: 0.3281 - acc: 0.9148\n",
      "learning rate: 0.105\n",
      "1796/1796 - 0s - loss: 0.1046 - acc: 0.9655\n",
      "learning rate: 0.106\n",
      "1796/1796 - 0s - loss: 0.0681 - acc: 0.9827\n",
      "learning rate: 0.105\n",
      "1796/1796 - 0s - loss: 0.0545 - acc: 0.9822\n",
      "learning rate: 0.104\n",
      "1796/1796 - 0s - loss: 0.0574 - acc: 0.9788\n",
      "learning rate: 0.103\n",
      "1796/1796 - 0s - loss: 0.0396 - acc: 0.9883\n",
      "learning rate: 0.104\n",
      "1796/1796 - 0s - loss: 0.0246 - acc: 0.9933\n",
      "learning rate: 0.103\n",
      "1796/1796 - 0s - loss: 0.0275 - acc: 0.9916\n",
      "learning rate: 0.102\n",
      "1796/1796 - 0s - loss: 0.0175 - acc: 0.9961\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 0.0122 - acc: 0.9978\n",
      "learning rate: 0.102\n",
      "1796/1796 - 0s - loss: 0.0103 - acc: 0.9983\n",
      "learning rate: 0.103\n",
      "1796/1796 - 0s - loss: 0.5281 - acc: 0.8875\n",
      "learning rate: 0.102\n",
      "1796/1796 - 0s - loss: 0.0730 - acc: 0.9800\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 0.0674 - acc: 0.9761\n",
      "learning rate: 0.102\n",
      "1796/1796 - 0s - loss: 0.0293 - acc: 0.9928\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 0.0280 - acc: 0.9950\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.0172 - acc: 0.9961\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 0.0405 - acc: 0.9911\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.0657 - acc: 0.9844\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 7.7808 - acc: 0.7918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 2.4510 - acc: 0.0963\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 2.3898 - acc: 0.0958\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 2.3526 - acc: 0.0952\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 2.3326 - acc: 0.0963\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 2.3213 - acc: 0.0952\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 2.3138 - acc: 0.1013\n",
      "learning rate: 0.102\n",
      "1796/1796 - 0s - loss: 2.3086 - acc: 0.1013\n",
      "episode: 6/100, score: 65, e: 0.62\n",
      "learning rate: 0.099\n",
      "1796/1796 - 1s - loss: 3.2181 - acc: 0.3313\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.6269 - acc: 0.8018\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 3.6071 - acc: 0.4582\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.5868 - acc: 0.8218\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 1.6363 - acc: 0.5451\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 0.4548 - acc: 0.8747\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 4.1621 - acc: 0.4059\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.9173 - acc: 0.7450\n",
      "learning rate: 0.101\n",
      "1796/1796 - 0s - loss: 0.6072 - acc: 0.8252\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 4.0074 - acc: 0.5846\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 1.1126 - acc: 0.6576\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 1.1540 - acc: 0.6715\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 0.6017 - acc: 0.8263\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 28.6766 - acc: 0.1453\n",
      "learning rate: 0.097\n",
      "1796/1796 - 0s - loss: 2.3568 - acc: 0.0963\n",
      "learning rate: 0.096\n",
      "1796/1796 - 0s - loss: 2.3350 - acc: 0.0963\n",
      "episode: 7/100, score: 15, e: 0.57\n",
      "learning rate: 0.101\n",
      "1796/1796 - 1s - loss: 2.8973 - acc: 0.3190\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.8437 - acc: 0.7361\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 0.3186 - acc: 0.9059\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.2476 - acc: 0.9315\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 0.0977 - acc: 0.9683\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 2.2076 - acc: 0.6548\n",
      "learning rate: 0.097\n",
      "1796/1796 - 0s - loss: 0.3624 - acc: 0.8914\n",
      "learning rate: 0.096\n",
      "1796/1796 - 0s - loss: 0.3232 - acc: 0.9154\n",
      "learning rate: 0.095\n",
      "1796/1796 - 0s - loss: 0.1443 - acc: 0.9532\n",
      "learning rate: 0.096\n",
      "1796/1796 - 0s - loss: nan - acc: 0.0952\n",
      "learning rate: 0.095\n",
      "1796/1796 - 0s - loss: nan - acc: 0.0991\n",
      "learning rate: 0.094\n",
      "1796/1796 - 0s - loss: nan - acc: 0.0991\n",
      "episode: 8/100, score: 11, e: 0.54\n",
      "learning rate: 0.099\n",
      "1796/1796 - 1s - loss: 3.3093 - acc: 0.3536\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 1.0750 - acc: 0.6487\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 0.8188 - acc: 0.7673\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 0.3932 - acc: 0.8764\n",
      "learning rate: 0.097\n",
      "1796/1796 - 0s - loss: 0.1336 - acc: 0.9577\n",
      "learning rate: 0.096\n",
      "1796/1796 - 0s - loss: 0.0620 - acc: 0.9833\n",
      "learning rate: 0.095\n",
      "1796/1796 - 0s - loss: 0.0558 - acc: 0.9883\n",
      "learning rate: 0.094\n",
      "1796/1796 - 0s - loss: 0.0289 - acc: 0.9922\n",
      "learning rate: 0.093\n",
      "1796/1796 - 0s - loss: 0.0195 - acc: 0.9961\n",
      "learning rate: 0.092\n",
      "1796/1796 - 0s - loss: 0.0132 - acc: 0.9978\n",
      "learning rate: 0.093\n",
      "1796/1796 - 0s - loss: 0.0114 - acc: 0.9978\n",
      "episode: 9/100, score: 10, e: 0.52\n",
      "learning rate: 0.099\n",
      "1796/1796 - 1s - loss: nan - acc: 0.1041\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: nan - acc: 0.0991\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: nan - acc: 0.0991\n",
      "episode: 10/100, score: 2, e: 0.51\n",
      "learning rate: 0.099\n",
      "1796/1796 - 1s - loss: 2.4388 - acc: 0.4560\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.8232 - acc: 0.7584\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 0.3044 - acc: 0.9120\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 1.9146 - acc: 0.6503\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 0.3309 - acc: 0.8998\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.1357 - acc: 0.9599\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 0.2320 - acc: 0.9415\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 0.0566 - acc: 0.9822\n",
      "learning rate: 0.097\n",
      "1796/1796 - 0s - loss: 0.0240 - acc: 0.9955\n",
      "learning rate: 0.096\n",
      "1796/1796 - 0s - loss: 0.0206 - acc: 0.9944\n",
      "learning rate: 0.095\n",
      "1796/1796 - 0s - loss: 0.0123 - acc: 0.9972\n",
      "learning rate: 0.094\n",
      "1796/1796 - 0s - loss: 0.0073 - acc: 0.9989\n",
      "learning rate: 0.093\n",
      "1796/1796 - 0s - loss: 0.0062 - acc: 0.9989\n",
      "episode: 11/100, score: 12, e: 0.48\n",
      "learning rate: 0.099\n",
      "1796/1796 - 1s - loss: 5.9453 - acc: 0.1787\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 4.2568 - acc: 0.1587\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 2.0446 - acc: 0.2762\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 1.2086 - acc: 0.6264\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 0.7767 - acc: 0.7689\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 0.7305 - acc: 0.7712\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 1.7067 - acc: 0.5406\n",
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.4557 - acc: 0.8664\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 3.3511 - acc: 0.3229\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 1.3053 - acc: 0.5501\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 1.6766 - acc: 0.4800\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 1.6493 - acc: 0.4777\n",
      "learning rate: 0.097\n",
      "1796/1796 - 0s - loss: 0.7603 - acc: 0.7706\n",
      "learning rate: 0.096\n",
      "1796/1796 - 0s - loss: 1.9395 - acc: 0.4911\n",
      "learning rate: 0.095\n",
      "1796/1796 - 0s - loss: 0.8145 - acc: 0.7411\n",
      "learning rate: 0.094\n",
      "1796/1796 - 0s - loss: 0.3369 - acc: 0.8992\n",
      "learning rate: 0.095\n",
      "1796/1796 - 0s - loss: 0.3406 - acc: 0.9026\n",
      "learning rate: 0.094\n",
      "1796/1796 - 0s - loss: 0.2067 - acc: 0.9382\n",
      "learning rate: 0.093\n",
      "1796/1796 - 0s - loss: 0.1094 - acc: 0.9683\n",
      "learning rate: 0.094\n",
      "1796/1796 - 0s - loss: 0.0768 - acc: 0.9788\n",
      "learning rate: 0.093\n",
      "1796/1796 - 0s - loss: 1.6576 - acc: 0.6509\n",
      "learning rate: 0.092\n",
      "1796/1796 - 0s - loss: 0.3201 - acc: 0.9076\n",
      "learning rate: 0.093\n",
      "1796/1796 - 0s - loss: 0.2292 - acc: 0.9376\n",
      "learning rate: 0.094\n",
      "1796/1796 - 0s - loss: 0.1077 - acc: 0.9705\n",
      "learning rate: 0.093\n",
      "1796/1796 - 0s - loss: 0.1142 - acc: 0.9621\n",
      "learning rate: 0.092\n",
      "1796/1796 - 0s - loss: 0.0533 - acc: 0.9839\n",
      "learning rate: 0.093\n",
      "1796/1796 - 0s - loss: 0.0373 - acc: 0.9900\n",
      "learning rate: 0.092\n",
      "1796/1796 - 0s - loss: 0.0368 - acc: 0.9883\n",
      "learning rate: 0.091\n",
      "1796/1796 - 0s - loss: 0.0281 - acc: 0.9922\n",
      "learning rate: 0.092\n",
      "1796/1796 - 0s - loss: 0.0230 - acc: 0.9933\n",
      "learning rate: 0.091\n",
      "1796/1796 - 0s - loss: 0.2253 - acc: 0.9438\n",
      "learning rate: 0.09\n",
      "1796/1796 - 0s - loss: 0.0559 - acc: 0.9833\n",
      "learning rate: 0.091\n",
      "1796/1796 - 0s - loss: 0.0601 - acc: 0.9805\n",
      "learning rate: 0.09\n",
      "1796/1796 - 0s - loss: 3.4442 - acc: 0.4248\n",
      "learning rate: 0.089\n",
      "1796/1796 - 0s - loss: 1.2377 - acc: 0.5863\n",
      "learning rate: 0.088\n",
      "1796/1796 - 0s - loss: 0.7468 - acc: 0.7339\n",
      "learning rate: 0.087\n",
      "1796/1796 - 0s - loss: 0.4088 - acc: 0.8853\n",
      "learning rate: 0.086\n",
      "1796/1796 - 0s - loss: 2.5700 - acc: 0.3252\n",
      "learning rate: 0.085\n",
      "1796/1796 - 0s - loss: 1.3802 - acc: 0.5245\n",
      "learning rate: 0.084\n",
      "1796/1796 - 0s - loss: 2.2580 - acc: 0.3959\n",
      "learning rate: 0.083\n",
      "1796/1796 - 0s - loss: 1.1149 - acc: 0.6320\n",
      "learning rate: 0.082\n",
      "1796/1796 - 0s - loss: 1.0479 - acc: 0.6693\n",
      "learning rate: 0.083\n",
      "1796/1796 - 0s - loss: 0.4925 - acc: 0.8602\n",
      "learning rate: 0.082\n",
      "1796/1796 - 0s - loss: 0.4725 - acc: 0.8753\n",
      "learning rate: 0.081\n",
      "1796/1796 - 0s - loss: 0.3500 - acc: 0.9070\n",
      "learning rate: 0.082\n",
      "1796/1796 - 0s - loss: 0.1531 - acc: 0.9543\n",
      "learning rate: 0.081\n",
      "1796/1796 - 0s - loss: 0.1042 - acc: 0.9666\n",
      "learning rate: 0.082\n",
      "1796/1796 - 0s - loss: 0.0970 - acc: 0.9649\n",
      "learning rate: 0.081\n",
      "1796/1796 - 0s - loss: 0.0626 - acc: 0.9805\n",
      "learning rate: 0.082\n",
      "1796/1796 - 0s - loss: 0.0497 - acc: 0.9833\n",
      "learning rate: 0.081\n",
      "1796/1796 - 0s - loss: 0.0429 - acc: 0.9872\n",
      "learning rate: 0.08\n",
      "1796/1796 - 0s - loss: 0.0311 - acc: 0.9900\n",
      "learning rate: 0.079\n",
      "1796/1796 - 0s - loss: 0.0252 - acc: 0.9933\n",
      "learning rate: 0.078\n",
      "1796/1796 - 0s - loss: 0.0252 - acc: 0.9911\n",
      "learning rate: 0.077\n",
      "1796/1796 - 0s - loss: 0.0223 - acc: 0.9928\n",
      "learning rate: 0.076\n",
      "1796/1796 - 0s - loss: 0.0200 - acc: 0.9933\n",
      "learning rate: 0.075\n",
      "1796/1796 - 0s - loss: 0.1095 - acc: 0.9710\n",
      "learning rate: 0.074\n",
      "1796/1796 - 0s - loss: 0.0164 - acc: 0.9955\n",
      "learning rate: 0.073\n",
      "1796/1796 - 0s - loss: 0.0122 - acc: 0.9978\n",
      "learning rate: 0.072\n",
      "1796/1796 - 0s - loss: 0.0100 - acc: 0.9978\n",
      "episode: 12/100, score: 59, e: 0.36\n",
      "learning rate: 0.099\n",
      "1796/1796 - 1s - loss: 3.1229 - acc: 0.3630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.1\n",
      "1796/1796 - 0s - loss: 0.8569 - acc: 0.7366\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 1.2656 - acc: 0.6782\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 0.2594 - acc: 0.9215\n",
      "learning rate: 0.099\n",
      "1796/1796 - 0s - loss: 0.1989 - acc: 0.9393\n",
      "learning rate: 0.098\n",
      "1796/1796 - 0s - loss: 0.0794 - acc: 0.9749\n",
      "learning rate: 0.097\n",
      "1796/1796 - 0s - loss: 0.0531 - acc: 0.9861\n",
      "learning rate: 0.096\n",
      "1796/1796 - 0s - loss: 0.0540 - acc: 0.9844\n",
      "learning rate: 0.095\n",
      "1796/1796 - 0s - loss: 0.0236 - acc: 0.9933\n",
      "learning rate: 0.094\n",
      "1796/1796 - 0s - loss: 0.0139 - acc: 0.9972\n",
      "learning rate: 0.093\n",
      "1796/1796 - 0s - loss: 0.0236 - acc: 0.9944\n",
      "learning rate: 0.092\n",
      "1796/1796 - 0s - loss: 0.0103 - acc: 0.9978\n",
      "learning rate: 0.093\n",
      "1796/1796 - 0s - loss: 0.0602 - acc: 0.9827\n",
      "learning rate: 0.092\n",
      "1796/1796 - 0s - loss: 0.0358 - acc: 0.9911\n",
      "learning rate: 0.091\n",
      "1796/1796 - 0s - loss: 0.0086 - acc: 0.9972\n",
      "learning rate: 0.09\n",
      "1796/1796 - 0s - loss: 0.0059 - acc: 0.9989\n",
      "learning rate: 0.089\n",
      "1796/1796 - 0s - loss: 0.0042 - acc: 0.9994\n",
      "learning rate: 0.088\n",
      "1796/1796 - 0s - loss: 0.0031 - acc: 0.9994\n",
      "episode: 13/100, score: 17, e: 0.33\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-b9ded442a2ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-6e35d6407a53>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mact_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# returns action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1076\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m           callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3251\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3253\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3254\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3255\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m       \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1341\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPISODES = 100\n",
    "IMPROVE = 0.0\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "state_size = 3\n",
    "action_size = 2\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "# agent.load(\"./save/cartpole-dqn.h5\")\n",
    "done = False\n",
    "batch_size = 32\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    \n",
    "    state = [np.inf, 0.0, lr]\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    model, loss_history, lrate = reset()\n",
    "    \n",
    "    for time in range(100):\n",
    "        \n",
    "        action = agent.act(state)\n",
    "        loss_history.lr.append(loss_history.lr[-1] - (1 - 2 * action) * 0.001)\n",
    "        callbacks_list = [loss_history, lrate]\n",
    "        \n",
    "        model.fit(X, y, \n",
    "                   epochs=1, \n",
    "                   batch_size=64, \n",
    "                   callbacks=callbacks_list, \n",
    "                   verbose=2)\n",
    "        \n",
    "        next_state = loss_history.losses[-1], loss_history.acc[-1], loss_history.lr[-1]\n",
    "        \n",
    "        improvement = loss_history.acc[-1] - loss_history.acc[-2]\n",
    "        reward = loss_history.acc[-1] + IMPROVE * improvement\n",
    "        done = improvement == 0.0\n",
    "        reward = -0.1 if improvement < 0.0 else reward\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        \n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
    "                  .format(e, EPISODES, time, agent.epsilon))\n",
    "            break\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent():\n",
    "    \n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma *\n",
    "                          np.amax(self.model.predict(next_state)[0]))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/1000, score: 16, e: 1.0\n",
      "episode: 1/1000, score: 11, e: 1.0\n",
      "episode: 2/1000, score: 16, e: 0.94\n",
      "episode: 3/1000, score: 10, e: 0.89\n",
      "episode: 4/1000, score: 55, e: 0.68\n",
      "episode: 5/1000, score: 10, e: 0.64\n",
      "episode: 6/1000, score: 19, e: 0.58\n",
      "episode: 7/1000, score: 16, e: 0.54\n",
      "episode: 8/1000, score: 11, e: 0.51\n",
      "episode: 9/1000, score: 12, e: 0.48\n",
      "episode: 10/1000, score: 10, e: 0.46\n",
      "episode: 11/1000, score: 12, e: 0.43\n",
      "episode: 12/1000, score: 9, e: 0.41\n",
      "episode: 13/1000, score: 10, e: 0.39\n",
      "episode: 14/1000, score: 8, e: 0.38\n",
      "episode: 15/1000, score: 10, e: 0.36\n",
      "episode: 16/1000, score: 8, e: 0.34\n",
      "episode: 17/1000, score: 9, e: 0.33\n",
      "episode: 18/1000, score: 8, e: 0.32\n",
      "episode: 19/1000, score: 144, e: 0.15\n",
      "episode: 20/1000, score: 125, e: 0.082\n",
      "episode: 21/1000, score: 57, e: 0.062\n",
      "episode: 22/1000, score: 43, e: 0.05\n",
      "episode: 23/1000, score: 17, e: 0.046\n",
      "episode: 24/1000, score: 50, e: 0.035\n",
      "episode: 25/1000, score: 23, e: 0.032\n",
      "episode: 26/1000, score: 20, e: 0.029\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-3934a42c125b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-6e35d6407a53>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 target = (reward + self.gamma *\n\u001b[0;32m---> 39\u001b[0;31m                           np.amax(self.model.predict(next_state)[0]))\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mtarget_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mtarget_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1076\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m           callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPISODES = 1000\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "# agent.load(\"./save/cartpole-dqn.h5\")\n",
    "done = False\n",
    "batch_size = 32\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    for time in range(500):\n",
    "        env.render()\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        reward = reward if not done else -10\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        \n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
    "                  .format(e, EPISODES, time, agent.epsilon))\n",
    "            break\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "sandbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
