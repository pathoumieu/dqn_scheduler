{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pa/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "X, y = digits.data[:-1], digits.target[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[1]\n",
    "num_classes = np.unique(y).shape[0]\n",
    "lr = 0.1\n",
    "\n",
    "y = pd.get_dummies(y).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define simple network and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_dim, num_classes, lr):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(lr=lr),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    return loss_history.lr[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    \n",
    "    def __init__(self, verbose, lr=0.01):\n",
    "        self.verbose = verbose\n",
    "        self.losses = [np.inf]\n",
    "        self.acc = [0.0]\n",
    "        self.lr = [lr]\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "#        self.lr.append(scheduler(len(self.losses)))\n",
    "        if epoch % 2 == 0:\n",
    "            print('learning rate: {}\\n'.format(np.round(self.lr[-1], 4)))\n",
    "        \n",
    "#        if epoch % self.verbose == 0:\n",
    "#            # you can access loss, accuracy in self.params['metrics']\n",
    "#            print('{} - loss: {} - acc: {}\\n'.format(epoch, self.losses[-1], self.acc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.1\n",
      "learning rate: 0.1\n",
      "learning rate: 0.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-6eb46718e7ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                    verbose=0)\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3251\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3253\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3254\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3255\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    871\u001b[0m   \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m       \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model(input_dim, num_classes, lr)\n",
    "\n",
    "loss_history = LossHistory(verbose=10)\n",
    "lrate = LearningRateScheduler(scheduler)\n",
    "callbacks_list = [loss_history, lrate]\n",
    "history = model.fit(X, y, \n",
    "                   epochs=10000, \n",
    "                   batch_size=64, \n",
    "                   callbacks=callbacks_list, \n",
    "                   verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent():\n",
    "    \n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma *\n",
    "                          np.amax(self.model.predict(next_state)[0]))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_env(lr):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    model = get_model(input_dim, num_classes, lr)\n",
    "    loss_history = LossHistory(verbose=1, lr=lr)\n",
    "    lrate = LearningRateScheduler(scheduler)\n",
    "    return model, loss_history, lrate\n",
    "\n",
    "\n",
    "def step_env(action, model, loss_history, lrate, improve_coeff=0.0, num_epochs=1):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Next state\n",
    "    if action == 0:\n",
    "        loss_history.lr.append(loss_history.lr[-1])    \n",
    "    elif action == 1:\n",
    "        loss_history.lr.append(loss_history.lr[-1] / 2.0)\n",
    "    elif action == 2:\n",
    "        loss_history.lr.append(loss_history.lr[-1] * 2.0)\n",
    "\n",
    "    callbacks_list = [loss_history, lrate]\n",
    "    model.fit(X, y, \n",
    "               epochs=num_epochs, \n",
    "               batch_size=64, \n",
    "               callbacks=callbacks_list, \n",
    "               verbose=2)\n",
    "    next_state = loss_history.losses[-1], loss_history.acc[-1], loss_history.lr[-1], \\\n",
    "    loss_history.losses[-2], loss_history.acc[-2]\n",
    "    # Reward\n",
    "    improvement = loss_history.acc[-1] - loss_history.acc[-2]\n",
    "    reward = loss_history.acc[-1] + improve_coeff * improvement\n",
    "    reward = -0.1 if improvement < 0.0 else reward\n",
    "    # Done\n",
    "    done = loss_history.acc[-1] == 1.0 or np.isnan(loss_history.losses[-1])\n",
    "    return next_state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.3418 - acc: 0.6464\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3712 - acc: 0.9092\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2648 - acc: 0.9365\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2111 - acc: 0.9493\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1933 - acc: 0.9532\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2071 - acc: 0.9471\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1358 - acc: 0.9666\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1063 - acc: 0.9738\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0934 - acc: 0.9827\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0911 - acc: 0.9816\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0841 - acc: 0.9850\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0891 - acc: 0.9794\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1681 - acc: 0.9532\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.8929 - acc: 0.8207\n",
      "learning rate: 0.08\n",
      "\n",
      "1796/1796 - 0s - loss: 0.6460 - acc: 0.8435\n",
      "learning rate: 0.08\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0877 - acc: 0.9733\n",
      "learning rate: 0.16\n",
      "\n",
      "1796/1796 - 0s - loss: nan - acc: 0.4198\n",
      "\n",
      "episode: 0/100, score: 0.4198218286037445, e: 1.0\n",
      "\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1584 - acc: 0.7133\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2363 - acc: 0.9337\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1353 - acc: 0.9666\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1556 - acc: 0.9638\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2521 - acc: 0.9449\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0706 - acc: 0.9822\n",
      "learning rate: 0.08\n",
      "\n",
      "1796/1796 - 0s - loss: 2.3661 - acc: 0.6225\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.7699 - acc: 0.8480\n",
      "learning rate: 0.08\n",
      "\n",
      "1796/1796 - 0s - loss: 0.8137 - acc: 0.7906\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2643 - acc: 0.9421\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2372 - acc: 0.9376\n",
      "learning rate: 0.08\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1055 - acc: 0.9666\n",
      "learning rate: 0.16\n",
      "\n",
      "1796/1796 - 0s - loss: 0.8814 - acc: 0.7645\n",
      "learning rate: 0.32\n",
      "\n",
      "1796/1796 - 0s - loss: nan - acc: 0.1308\n",
      "\n",
      "episode: 1/100, score: 0.1308463215827942, e: 1.0\n",
      "\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2556 - acc: 0.6470\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.4546 - acc: 0.8731\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2149 - acc: 0.9510\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1787 - acc: 0.9605\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1645 - acc: 0.9638\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1472 - acc: 0.9677\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1368 - acc: 0.9705\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1184 - acc: 0.9761\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1120 - acc: 0.9777\n",
      "learning rate: 0.0006\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1077 - acc: 0.9794\n",
      "learning rate: 0.0006\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1125 - acc: 0.9749\n",
      "learning rate: 0.0003\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1044 - acc: 0.9805\n",
      "learning rate: 0.0003\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1035 - acc: 0.9800\n",
      "learning rate: 0.0003\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1029 - acc: 0.9805\n",
      "learning rate: 0.0002\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1019 - acc: 0.9800\n",
      "learning rate: 0.0002\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1016 - acc: 0.9800\n",
      "learning rate: 0.0001\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1012 - acc: 0.9800\n",
      "learning rate: 0.0001\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1010 - acc: 0.9800\n",
      "learning rate: 0.0002\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1009 - acc: 0.9800\n",
      "learning rate: 0.0003\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1007 - acc: 0.9811\n",
      "learning rate: 0.0002\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1000 - acc: 0.9805\n",
      "learning rate: 0.0002\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0997 - acc: 0.9811\n",
      "learning rate: 0.0002\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0994 - acc: 0.9827\n",
      "learning rate: 0.0002\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0990 - acc: 0.9827\n",
      "learning rate: 0.0002\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0987 - acc: 0.9822\n",
      "learning rate: 0.0001\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0983 - acc: 0.9827\n",
      "learning rate: 0.0001\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0982 - acc: 0.9827\n",
      "learning rate: 0.0\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0979 - acc: 0.9822\n",
      "learning rate: 0.0\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0979 - acc: 0.9822\n",
      "learning rate: 0.0\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0978 - acc: 0.9822\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1069 - acc: 0.6620\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3175 - acc: 0.9237\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1889 - acc: 0.9555\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1358 - acc: 0.9710\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1268 - acc: 0.9666\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2631 - acc: 0.9393\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.8953 - acc: 0.8363\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1380 - acc: 0.9588\n",
      "learning rate: 0.08\n",
      "\n",
      "1796/1796 - 0s - loss: 1.1375 - acc: 0.7494\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1403 - acc: 0.9605\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1338 - acc: 0.9677\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0546 - acc: 0.9905\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0500 - acc: 0.9883\n",
      "learning rate: 0.08\n",
      "\n",
      "1796/1796 - 0s - loss: 0.6302 - acc: 0.9031\n",
      "learning rate: 0.16\n",
      "\n",
      "1796/1796 - 0s - loss: 2.7735 - acc: 0.3452\n",
      "learning rate: 0.08\n",
      "\n",
      "1796/1796 - 0s - loss: 3.8199 - acc: 0.1598\n",
      "learning rate: 0.08\n",
      "\n",
      "1796/1796 - 0s - loss: 1.9128 - acc: 0.2929\n",
      "learning rate: 0.16\n",
      "\n",
      "1796/1796 - 0s - loss: 1.9798 - acc: 0.3458\n",
      "learning rate: 0.08\n",
      "\n",
      "1796/1796 - 0s - loss: 1.0454 - acc: 0.6604\n",
      "learning rate: 0.16\n",
      "\n",
      "1796/1796 - 0s - loss: 1.3364 - acc: 0.5752\n",
      "learning rate: 0.16\n",
      "\n",
      "1796/1796 - 0s - loss: 1.0732 - acc: 0.6592\n",
      "learning rate: 0.16\n",
      "\n",
      "1796/1796 - 0s - loss: 0.5077 - acc: 0.8430\n",
      "learning rate: 0.08\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1572 - acc: 0.9499\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0917 - acc: 0.9738\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0841 - acc: 0.9727\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0651 - acc: 0.9794\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0596 - acc: 0.9811\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0556 - acc: 0.9839\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0555 - acc: 0.9833\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0559 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2178 - acc: 0.6871\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.4740 - acc: 0.8881\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2208 - acc: 0.9427\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1657 - acc: 0.9621\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1370 - acc: 0.9683\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1199 - acc: 0.9716\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0991 - acc: 0.9805\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0944 - acc: 0.9788\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0852 - acc: 0.9800\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0796 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0658 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0609 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0545 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0485 - acc: 0.9950\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0470 - acc: 0.9950\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0418 - acc: 0.9955\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0406 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0423 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0565 - acc: 0.9900\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0434 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0319 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0300 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0258 - acc: 0.9978\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0248 - acc: 0.9978\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0243 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0243 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0248 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0235 - acc: 0.9978\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0277 - acc: 0.9950\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 1.0716 - acc: 0.8029\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1163 - acc: 0.6709\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.5216 - acc: 0.8753\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2030 - acc: 0.9527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1566 - acc: 0.9671\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1315 - acc: 0.9761\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1120 - acc: 0.9811\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1043 - acc: 0.9805\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0953 - acc: 0.9839\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0917 - acc: 0.9827\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0856 - acc: 0.9839\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0804 - acc: 0.9855\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0772 - acc: 0.9844\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0696 - acc: 0.9916\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0669 - acc: 0.9905\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0631 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0628 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0572 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0519 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0468 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0438 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0385 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0352 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0318 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0316 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0294 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0285 - acc: 0.9978\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0591 - acc: 0.9866\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0513 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1048 - acc: 0.9761\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0262 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1330 - acc: 0.6643\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3213 - acc: 0.9321\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2282 - acc: 0.9493\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1695 - acc: 0.9588\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1506 - acc: 0.9610\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1155 - acc: 0.9738\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1024 - acc: 0.9761\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0729 - acc: 0.9866\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0695 - acc: 0.9872\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0664 - acc: 0.9900\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0607 - acc: 0.9911\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0567 - acc: 0.9916\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0560 - acc: 0.9922\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0553 - acc: 0.9928\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0549 - acc: 0.9922\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0540 - acc: 0.9933\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0523 - acc: 0.9928\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0507 - acc: 0.9944\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0496 - acc: 0.9950\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0489 - acc: 0.9950\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0492 - acc: 0.9939\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0470 - acc: 0.9944\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0468 - acc: 0.9950\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0459 - acc: 0.9955\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0451 - acc: 0.9950\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0457 - acc: 0.9950\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0445 - acc: 0.9950\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0429 - acc: 0.9950\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0420 - acc: 0.9961\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0421 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1371 - acc: 0.6565\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.4020 - acc: 0.8959\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2180 - acc: 0.9493\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1673 - acc: 0.9616\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1577 - acc: 0.9571\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1003 - acc: 0.9827\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0858 - acc: 0.9827\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0907 - acc: 0.9800\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0615 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0590 - acc: 0.9894\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0492 - acc: 0.9922\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0563 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0480 - acc: 0.9928\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0396 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0408 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0391 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0352 - acc: 0.9939\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0295 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0302 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0279 - acc: 0.9967\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0392 - acc: 0.9933\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0244 - acc: 0.9972\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0225 - acc: 0.9983\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0220 - acc: 0.9983\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0214 - acc: 0.9994\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0230 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0209 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0217 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0198 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0188 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.4051 - acc: 0.6565\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.4856 - acc: 0.8797\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3016 - acc: 0.9220\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2654 - acc: 0.9321\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1228 - acc: 0.9705\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1282 - acc: 0.9638\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.6149 - acc: 0.8976\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1161 - acc: 0.9727\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0962 - acc: 0.9749\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0719 - acc: 0.9822\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0561 - acc: 0.9883\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 1.8385 - acc: 0.7734\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2427 - acc: 0.9293\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0879 - acc: 0.9783\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1996 - acc: 0.9549\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0564 - acc: 0.9850\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0426 - acc: 0.9911\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0308 - acc: 0.9950\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0219 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0180 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0167 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0162 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0158 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0153 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0151 - acc: 0.9983\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0146 - acc: 0.9983\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0143 - acc: 0.9983\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0140 - acc: 0.9983\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0137 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0138 - acc: 0.9978\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 1s - loss: 1.5041 - acc: 0.7010\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2754 - acc: 0.9304\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1543 - acc: 0.9621\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1046 - acc: 0.9722\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3293 - acc: 0.9343\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0793 - acc: 0.9822\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0641 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0465 - acc: 0.9950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0417 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0388 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0366 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0322 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0305 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0284 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0621 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0265 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0246 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0226 - acc: 0.9983\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0210 - acc: 0.9989\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0200 - acc: 0.9989\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0194 - acc: 0.9983\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0190 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0190 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0186 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0177 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0165 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0160 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0155 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0146 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0140 - acc: 0.9983\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 1s - loss: 2.0818 - acc: 0.6364\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3013 - acc: 0.9271\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.4473 - acc: 0.8853\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0995 - acc: 0.9800\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0766 - acc: 0.9844\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0667 - acc: 0.9861\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0467 - acc: 0.9905\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0383 - acc: 0.9933\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0336 - acc: 0.9950\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0595 - acc: 0.9839\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0252 - acc: 0.9972\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0216 - acc: 0.9967\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0192 - acc: 0.9994\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0170 - acc: 0.9983\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0146 - acc: 1.0000\n",
      "\n",
      "episode: 10/100, score: 1.0, e: 0.28\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2448 - acc: 0.6882\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3368 - acc: 0.9259\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2406 - acc: 0.9499\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2040 - acc: 0.9549\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1678 - acc: 0.9633\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1457 - acc: 0.9705\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1242 - acc: 0.9777\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1112 - acc: 0.9794\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1058 - acc: 0.9816\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1007 - acc: 0.9822\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0968 - acc: 0.9833\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0924 - acc: 0.9827\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0877 - acc: 0.9839\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0871 - acc: 0.9833\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0810 - acc: 0.9850\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0775 - acc: 0.9872\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0758 - acc: 0.9855\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0743 - acc: 0.9878\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0731 - acc: 0.9872\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0716 - acc: 0.9900\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0710 - acc: 0.9878\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0693 - acc: 0.9883\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0680 - acc: 0.9911\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0682 - acc: 0.9900\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0661 - acc: 0.9911\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0662 - acc: 0.9900\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0644 - acc: 0.9905\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0629 - acc: 0.9928\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0618 - acc: 0.9928\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0611 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2361 - acc: 0.6810\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3342 - acc: 0.9131\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3419 - acc: 0.9215\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1612 - acc: 0.9605\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1462 - acc: 0.9605\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1473 - acc: 0.9671\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0878 - acc: 0.9811\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0762 - acc: 0.9833\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0668 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0600 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0543 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0479 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0435 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0587 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0373 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0469 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0342 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0293 - acc: 0.9972\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0330 - acc: 0.9961\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 1.0096 - acc: 0.8569\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1037 - acc: 0.9794\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.4668 - acc: 0.9182\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0667 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0525 - acc: 0.9911\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0450 - acc: 0.9933\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0416 - acc: 0.9928\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0383 - acc: 0.9944\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0360 - acc: 0.9950\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0339 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0326 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0359 - acc: 0.7149\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3266 - acc: 0.9126\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1917 - acc: 0.9527\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1563 - acc: 0.9649\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1190 - acc: 0.9761\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1027 - acc: 0.9816\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0861 - acc: 0.9833\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0705 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0630 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0616 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0497 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0448 - acc: 0.9939\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0558 - acc: 0.9872\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3896 - acc: 0.9165\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3561 - acc: 0.9237\n",
      "learning rate: 0.04\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0532 - acc: 0.9883\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0289 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0226 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0200 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0190 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0173 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0178 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0152 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0144 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0138 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0128 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0120 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0116 - acc: 0.9994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0115 - acc: 0.9994\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0194 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1264 - acc: 0.7116\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3209 - acc: 0.9204\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2088 - acc: 0.9454\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1592 - acc: 0.9560\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1384 - acc: 0.9671\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1113 - acc: 0.9733\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0929 - acc: 0.9783\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0833 - acc: 0.9811\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0731 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0822 - acc: 0.9822\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0596 - acc: 0.9900\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0752 - acc: 0.9805\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0528 - acc: 0.9894\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0524 - acc: 0.9894\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0477 - acc: 0.9900\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0399 - acc: 0.9916\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0280 - acc: 0.9967\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0278 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0199 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0186 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0172 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0173 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0165 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0156 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0156 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0141 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0137 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0132 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0126 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0147 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0756 - acc: 0.6876\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3429 - acc: 0.9098\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1890 - acc: 0.9521\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1207 - acc: 0.9716\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1048 - acc: 0.9761\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0827 - acc: 0.9844\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0872 - acc: 0.9827\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0716 - acc: 0.9866\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0687 - acc: 0.9894\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0633 - acc: 0.9889\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0587 - acc: 0.9905\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0531 - acc: 0.9928\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0501 - acc: 0.9939\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0471 - acc: 0.9933\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0458 - acc: 0.9944\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0430 - acc: 0.9939\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0429 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0426 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0371 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0348 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0304 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0281 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0246 - acc: 0.9983\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0238 - acc: 0.9989\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0227 - acc: 0.9989\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0221 - acc: 0.9989\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0225 - acc: 0.9989\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0206 - acc: 0.9983\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0197 - acc: 0.9994\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0196 - acc: 0.9994\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 1s - loss: 1.4530 - acc: 0.6052\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.4490 - acc: 0.8792\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2980 - acc: 0.9248\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2132 - acc: 0.9516\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1742 - acc: 0.9605\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1473 - acc: 0.9722\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1260 - acc: 0.9788\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1218 - acc: 0.9755\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1021 - acc: 0.9816\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0926 - acc: 0.9822\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0872 - acc: 0.9833\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1229 - acc: 0.9722\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0782 - acc: 0.9811\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0710 - acc: 0.9872\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0639 - acc: 0.9866\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0590 - acc: 0.9889\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0625 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0656 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0516 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0445 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0452 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0399 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1267 - acc: 0.9677\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0461 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0311 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0274 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0243 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0264 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0212 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0200 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2285 - acc: 0.6386\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3404 - acc: 0.9109\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2316 - acc: 0.9421\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1704 - acc: 0.9555\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1333 - acc: 0.9671\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1113 - acc: 0.9738\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0948 - acc: 0.9800\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0774 - acc: 0.9861\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0719 - acc: 0.9850\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0680 - acc: 0.9889\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0674 - acc: 0.9889\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0617 - acc: 0.9911\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0598 - acc: 0.9933\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0567 - acc: 0.9939\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0540 - acc: 0.9928\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0521 - acc: 0.9944\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0512 - acc: 0.9922\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0496 - acc: 0.9922\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0487 - acc: 0.9933\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0478 - acc: 0.9950\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0469 - acc: 0.9939\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0460 - acc: 0.9950\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0445 - acc: 0.9961\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0436 - acc: 0.9955\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0425 - acc: 0.9967\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0419 - acc: 0.9961\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0410 - acc: 0.9972\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0401 - acc: 0.9961\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0394 - acc: 0.9967\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0391 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1038 - acc: 0.6565\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3148 - acc: 0.9209\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2103 - acc: 0.9477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1582 - acc: 0.9621\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1241 - acc: 0.9722\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1242 - acc: 0.9666\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0918 - acc: 0.9794\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0762 - acc: 0.9866\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0695 - acc: 0.9878\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0664 - acc: 0.9878\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0649 - acc: 0.9866\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0579 - acc: 0.9905\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0544 - acc: 0.9933\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0514 - acc: 0.9939\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0486 - acc: 0.9955\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0473 - acc: 0.9950\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0515 - acc: 0.9911\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0422 - acc: 0.9961\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0413 - acc: 0.9961\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0407 - acc: 0.9967\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0401 - acc: 0.9967\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0397 - acc: 0.9967\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0392 - acc: 0.9967\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0387 - acc: 0.9967\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0382 - acc: 0.9967\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0377 - acc: 0.9967\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0373 - acc: 0.9967\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0370 - acc: 0.9967\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0368 - acc: 0.9961\n",
      "learning rate: 0.0012\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0362 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1420 - acc: 0.7116\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2638 - acc: 0.9382\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1977 - acc: 0.9510\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1359 - acc: 0.9705\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2418 - acc: 0.9421\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0782 - acc: 0.9833\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0636 - acc: 0.9861\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0492 - acc: 0.9911\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0392 - acc: 0.9950\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0387 - acc: 0.9928\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0326 - acc: 0.9955\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0265 - acc: 0.9961\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0250 - acc: 0.9967\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0210 - acc: 0.9972\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0271 - acc: 0.9939\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0152 - acc: 0.9989\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0136 - acc: 0.9994\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0130 - acc: 0.9994\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0112 - acc: 1.0000\n",
      "\n",
      "episode: 19/100, score: 1.0, e: 0.077\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1461 - acc: 0.6910\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2871 - acc: 0.9304\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1940 - acc: 0.9538\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1414 - acc: 0.9655\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1112 - acc: 0.9772\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0911 - acc: 0.9805\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0776 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0700 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0599 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0534 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0482 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0438 - acc: 0.9944\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0379 - acc: 0.9955\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0355 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0344 - acc: 0.9961\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0330 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0319 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0303 - acc: 0.9983\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0288 - acc: 0.9978\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0283 - acc: 0.9983\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0278 - acc: 0.9983\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0269 - acc: 0.9989\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0267 - acc: 0.9983\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0263 - acc: 0.9983\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0254 - acc: 0.9989\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0253 - acc: 0.9983\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0251 - acc: 0.9989\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0243 - acc: 0.9989\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0245 - acc: 0.9983\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0240 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.4058 - acc: 0.6860\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3278 - acc: 0.9198\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2132 - acc: 0.9532\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1635 - acc: 0.9660\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1290 - acc: 0.9716\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1079 - acc: 0.9777\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1340 - acc: 0.9666\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0819 - acc: 0.9816\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0701 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0616 - acc: 0.9900\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0558 - acc: 0.9900\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0489 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0440 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0411 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0402 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0348 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0337 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0306 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0331 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0359 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0259 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0234 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0215 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0198 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0194 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0177 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0166 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0170 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0152 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0155 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1469 - acc: 0.7055\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3352 - acc: 0.9176\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1959 - acc: 0.9521\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3507 - acc: 0.9243\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1172 - acc: 0.9772\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0968 - acc: 0.9783\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0846 - acc: 0.9827\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0724 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0642 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0557 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0534 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0452 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0425 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0380 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0375 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0320 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0290 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0273 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0263 - acc: 0.9983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0244 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0251 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0220 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0206 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0191 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1954 - acc: 0.9699\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0236 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0199 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0179 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0160 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0162 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1891 - acc: 0.6927\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3323 - acc: 0.9115\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2003 - acc: 0.9527\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1628 - acc: 0.9577\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1317 - acc: 0.9633\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1053 - acc: 0.9744\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0887 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0723 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0786 - acc: 0.9833\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0716 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0543 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0487 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0463 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0403 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0361 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0351 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0300 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0291 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0289 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0267 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0243 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0220 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0208 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0196 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0194 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0185 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0174 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0161 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0168 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0160 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1850 - acc: 0.6648\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3220 - acc: 0.9137\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2095 - acc: 0.9427\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1622 - acc: 0.9588\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1349 - acc: 0.9677\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0994 - acc: 0.9788\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0871 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0953 - acc: 0.9749\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1959 - acc: 0.9616\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0754 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0520 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0473 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0436 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0404 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0366 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0332 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0314 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0282 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0278 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0256 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0243 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0338 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0214 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0201 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0185 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0179 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0168 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0158 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0154 - acc: 0.9989\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0141 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0824 - acc: 0.6815\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3074 - acc: 0.9187\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2002 - acc: 0.9493\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1431 - acc: 0.9688\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1238 - acc: 0.9749\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1018 - acc: 0.9794\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1913 - acc: 0.9649\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0741 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0640 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0618 - acc: 0.9900\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0549 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0508 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0459 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0386 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0538 - acc: 0.9900\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0358 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0435 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0306 - acc: 0.9972\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0364 - acc: 0.9950\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0281 - acc: 0.9961\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0905 - acc: 0.9833\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0230 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0176 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0245 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0169 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0151 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3436 - acc: 0.9438\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0313 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0226 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0187 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0484 - acc: 0.7249\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3571 - acc: 0.9070\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2012 - acc: 0.9438\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1637 - acc: 0.9577\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1180 - acc: 0.9716\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0974 - acc: 0.9805\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1151 - acc: 0.9744\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0739 - acc: 0.9855\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1350 - acc: 0.9722\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0607 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0529 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0476 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0924 - acc: 0.9800\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0485 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0430 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0342 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0326 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0295 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0269 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0262 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0237 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0226 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0210 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0207 - acc: 0.9978\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0216 - acc: 0.9972\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0209 - acc: 0.9978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0173 - acc: 0.9994\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0174 - acc: 0.9983\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0146 - acc: 0.9989\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0197 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2013 - acc: 0.6776\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2606 - acc: 0.9365\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1624 - acc: 0.9616\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1330 - acc: 0.9683\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2093 - acc: 0.9521\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0866 - acc: 0.9800\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0719 - acc: 0.9889\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0580 - acc: 0.9894\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0538 - acc: 0.9939\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0499 - acc: 0.9939\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0478 - acc: 0.9950\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0449 - acc: 0.9961\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0434 - acc: 0.9944\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0407 - acc: 0.9950\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0381 - acc: 0.9961\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0363 - acc: 0.9967\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0347 - acc: 0.9967\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0330 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0318 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0308 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0299 - acc: 0.9978\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0281 - acc: 0.9978\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0272 - acc: 0.9978\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0266 - acc: 0.9978\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0267 - acc: 0.9978\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0257 - acc: 0.9978\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0253 - acc: 0.9978\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0248 - acc: 0.9978\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0245 - acc: 0.9983\n",
      "learning rate: 0.0025\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0240 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0484 - acc: 0.6876\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2759 - acc: 0.9226\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1899 - acc: 0.9532\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1680 - acc: 0.9621\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1889 - acc: 0.9566\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0968 - acc: 0.9805\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0791 - acc: 0.9833\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0667 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0628 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0517 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0467 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0431 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0408 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0357 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0318 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0309 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0298 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0332 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0243 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0243 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0225 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0210 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0194 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0187 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0175 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0169 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0159 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0151 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0146 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0137 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1654 - acc: 0.6982\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3375 - acc: 0.9109\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1967 - acc: 0.9521\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1738 - acc: 0.9560\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1195 - acc: 0.9716\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0982 - acc: 0.9788\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0855 - acc: 0.9816\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0760 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0694 - acc: 0.9850\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0577 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0541 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1217 - acc: 0.9699\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0428 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0774 - acc: 0.9827\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0376 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0334 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0318 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0276 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0267 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0240 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0234 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0223 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0205 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0199 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0182 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0169 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0168 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0162 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0150 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0149 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.5275 - acc: 0.6648\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3277 - acc: 0.9115\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2082 - acc: 0.9477\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1976 - acc: 0.9477\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1095 - acc: 0.9744\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1760 - acc: 0.9571\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0785 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0715 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0570 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0487 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0409 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0485 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0356 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0319 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0464 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0281 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0246 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0233 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0212 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0192 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0188 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0176 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0165 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0152 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0148 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0140 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0135 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0125 - acc: 1.0000\n",
      "\n",
      "episode: 30/100, score: 1.0, e: 0.015\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1411 - acc: 0.6732\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2595 - acc: 0.9382\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1788 - acc: 0.9521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1307 - acc: 0.9627\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1040 - acc: 0.9744\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0797 - acc: 0.9827\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0714 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0572 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0596 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0495 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0411 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0363 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0335 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0333 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0282 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0263 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0228 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0224 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0216 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0197 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0190 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0179 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0162 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0158 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0148 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0141 - acc: 1.0000\n",
      "\n",
      "episode: 31/100, score: 1.0, e: 0.013\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2300 - acc: 0.6804\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3117 - acc: 0.9209\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1972 - acc: 0.9555\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1696 - acc: 0.9516\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1701 - acc: 0.9588\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1066 - acc: 0.9727\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0849 - acc: 0.9850\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0720 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0641 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0613 - acc: 0.9900\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0526 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0471 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0417 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0503 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0344 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0321 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0294 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0284 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0275 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0252 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0231 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0226 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0198 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0190 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0184 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0170 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0157 - acc: 1.0000\n",
      "\n",
      "episode: 32/100, score: 1.0, e: 0.012\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1584 - acc: 0.6865\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2877 - acc: 0.9276\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3055 - acc: 0.9182\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2053 - acc: 0.9499\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1163 - acc: 0.9755\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0944 - acc: 0.9816\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0813 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0752 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0650 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0563 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0512 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0546 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0401 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0389 - acc: 0.9928\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0895 - acc: 0.9839\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0348 - acc: 0.9967\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0319 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0305 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0286 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0276 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0261 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0255 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0245 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0238 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0228 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0221 - acc: 0.9983\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0215 - acc: 0.9983\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0214 - acc: 0.9983\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0216 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0195 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2610 - acc: 0.6927\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3218 - acc: 0.9209\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3077 - acc: 0.9198\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1527 - acc: 0.9655\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1434 - acc: 0.9633\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1139 - acc: 0.9710\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1087 - acc: 0.9733\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0766 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0663 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0584 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0523 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0481 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0435 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0406 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0366 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0447 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0358 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0309 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0895 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0285 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0264 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0244 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0224 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0213 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0199 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0183 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0179 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0213 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0166 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0152 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.6069 - acc: 0.6431\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3822 - acc: 0.9087\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2181 - acc: 0.9438\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1522 - acc: 0.9666\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1174 - acc: 0.9738\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0976 - acc: 0.9822\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0848 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0717 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0796 - acc: 0.9811\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0570 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0514 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0442 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0400 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0372 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0337 - acc: 0.9983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0314 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0295 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0267 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0249 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0247 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0392 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0230 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0216 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0196 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0262 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0171 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0159 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0157 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0162 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0140 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.4592 - acc: 0.6620\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3156 - acc: 0.9187\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2111 - acc: 0.9516\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1540 - acc: 0.9666\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1346 - acc: 0.9694\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1095 - acc: 0.9777\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0915 - acc: 0.9811\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0796 - acc: 0.9805\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0720 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0741 - acc: 0.9827\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0593 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0548 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0478 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0468 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0738 - acc: 0.9827\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0389 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0370 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0320 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0309 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0276 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0264 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0238 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0234 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0257 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0245 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0196 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0180 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0179 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0182 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0159 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.3271 - acc: 0.6876\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3087 - acc: 0.9254\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1840 - acc: 0.9543\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2132 - acc: 0.9504\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1186 - acc: 0.9705\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0916 - acc: 0.9816\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0897 - acc: 0.9811\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0660 - acc: 0.9900\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0594 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0538 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0483 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0431 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0403 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0363 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0338 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0300 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0289 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0273 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0245 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0231 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0222 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0209 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0207 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0185 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0174 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0177 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0156 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0152 - acc: 1.0000\n",
      "\n",
      "episode: 37/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0320 - acc: 0.7378\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3189 - acc: 0.9193\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1897 - acc: 0.9532\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1486 - acc: 0.9716\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1166 - acc: 0.9749\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0998 - acc: 0.9811\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0951 - acc: 0.9827\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0856 - acc: 0.9844\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0839 - acc: 0.9844\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0736 - acc: 0.9866\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0676 - acc: 0.9894\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0639 - acc: 0.9883\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0592 - acc: 0.9905\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0574 - acc: 0.9911\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0535 - acc: 0.9911\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0540 - acc: 0.9933\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0489 - acc: 0.9922\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0465 - acc: 0.9928\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0449 - acc: 0.9928\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0411 - acc: 0.9950\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0399 - acc: 0.9955\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0390 - acc: 0.9950\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0372 - acc: 0.9967\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0373 - acc: 0.9950\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0341 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0325 - acc: 0.9967\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0313 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0307 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0292 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0283 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.3140 - acc: 0.6492\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3616 - acc: 0.9120\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2660 - acc: 0.9360\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2963 - acc: 0.9371\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1335 - acc: 0.9688\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1123 - acc: 0.9777\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1091 - acc: 0.9733\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1050 - acc: 0.9733\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0747 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0679 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0605 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0571 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0512 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0452 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0419 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0405 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0365 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0353 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0308 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0315 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0309 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0341 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2602 - acc: 0.9588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0353 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0271 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0242 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0229 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0200 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0186 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0180 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0443 - acc: 0.6938\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2662 - acc: 0.9393\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1613 - acc: 0.9610\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1308 - acc: 0.9671\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2846 - acc: 0.9410\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0936 - acc: 0.9783\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1060 - acc: 0.9744\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0630 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0752 - acc: 0.9822\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0505 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0587 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0405 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0388 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0333 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0307 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0280 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0256 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0245 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0229 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0213 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0200 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0191 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0177 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0173 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0164 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0159 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0148 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0141 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0298 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0144 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 0.9942 - acc: 0.7171\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3349 - acc: 0.9126\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1970 - acc: 0.9538\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1412 - acc: 0.9694\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1251 - acc: 0.9694\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0902 - acc: 0.9827\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0752 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0732 - acc: 0.9833\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0605 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0526 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0478 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0456 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0391 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0368 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0344 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0325 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0302 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0340 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0264 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0243 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0225 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0223 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0200 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0196 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0182 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0174 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0167 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0154 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0155 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0140 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.3153 - acc: 0.6553\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3126 - acc: 0.9282\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2019 - acc: 0.9521\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1557 - acc: 0.9621\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1277 - acc: 0.9705\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1006 - acc: 0.9766\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0846 - acc: 0.9816\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0715 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0629 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0558 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0563 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0479 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0413 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0371 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0352 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1512 - acc: 0.9671\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0340 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0350 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0268 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0240 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0221 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0212 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0191 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0189 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0170 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0159 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0148 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0149 - acc: 1.0000\n",
      "\n",
      "episode: 42/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0595 - acc: 0.7255\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3004 - acc: 0.9271\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1597 - acc: 0.9716\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1210 - acc: 0.9777\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0966 - acc: 0.9788\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0847 - acc: 0.9827\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1127 - acc: 0.9727\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0629 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0572 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0591 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0435 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0405 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0357 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0334 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0316 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0288 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0268 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0251 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0225 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0210 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0207 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0194 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0184 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0187 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0159 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0151 - acc: 1.0000\n",
      "\n",
      "episode: 43/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2729 - acc: 0.6698\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3239 - acc: 0.9165\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2672 - acc: 0.9354\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1606 - acc: 0.9644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1297 - acc: 0.9733\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0984 - acc: 0.9800\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1406 - acc: 0.9649\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0995 - acc: 0.9727\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0663 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0573 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0531 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0439 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0394 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0368 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0344 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0318 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0285 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0264 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0277 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0242 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0220 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0210 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0569 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0193 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0194 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0210 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0169 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0149 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0141 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0135 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1505 - acc: 0.7249\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3066 - acc: 0.9165\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2009 - acc: 0.9477\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1542 - acc: 0.9621\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1520 - acc: 0.9582\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1071 - acc: 0.9733\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1999 - acc: 0.9566\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0811 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0697 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0620 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0525 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0491 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0487 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0428 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0403 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0352 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0334 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0316 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0308 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0273 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0249 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0242 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0222 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0236 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0215 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0206 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0183 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0174 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0172 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0162 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1953 - acc: 0.6810\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3180 - acc: 0.9159\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1822 - acc: 0.9532\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1367 - acc: 0.9722\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1140 - acc: 0.9766\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0922 - acc: 0.9805\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0765 - acc: 0.9850\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0721 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0594 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0655 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0480 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0416 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0373 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0359 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0333 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0299 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0274 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0281 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0251 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0227 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0211 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0203 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0187 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0182 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0174 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1156 - acc: 0.9800\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0174 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0160 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0149 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0137 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0825 - acc: 0.7238\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3736 - acc: 0.9120\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1899 - acc: 0.9516\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1514 - acc: 0.9638\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1156 - acc: 0.9744\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1012 - acc: 0.9772\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0851 - acc: 0.9827\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1087 - acc: 0.9727\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0652 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0568 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0989 - acc: 0.9755\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0479 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0426 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0382 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0344 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0428 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0305 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0277 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0282 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0239 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0231 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0210 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0202 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0188 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0174 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0165 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0161 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0150 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0144 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0133 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.5190 - acc: 0.6459\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3668 - acc: 0.9137\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2223 - acc: 0.9482\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1609 - acc: 0.9621\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1296 - acc: 0.9705\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1246 - acc: 0.9677\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2101 - acc: 0.9527\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0813 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0707 - acc: 0.9855\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0608 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0555 - acc: 0.9894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0483 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0458 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0418 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0385 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0370 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0339 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0311 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0302 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0284 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0253 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0236 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0229 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0247 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0210 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0198 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0196 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0178 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0180 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0188 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.3377 - acc: 0.6893\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3176 - acc: 0.9204\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2022 - acc: 0.9493\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1561 - acc: 0.9599\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1832 - acc: 0.9538\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1311 - acc: 0.9683\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0863 - acc: 0.9816\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0759 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0674 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0608 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0523 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0526 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0435 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0403 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0437 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0349 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0324 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0303 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0274 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0257 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0257 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0231 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0216 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0208 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0200 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0187 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0195 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0175 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0164 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0154 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0334 - acc: 0.7283\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2714 - acc: 0.9376\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2079 - acc: 0.9482\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1523 - acc: 0.9649\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1034 - acc: 0.9822\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0917 - acc: 0.9822\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0780 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0709 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0604 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0504 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0472 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0427 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0378 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0353 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0318 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1224 - acc: 0.9749\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0304 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0261 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0461 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0223 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0199 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0183 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0178 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0166 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0169 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0143 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0139 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0133 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0125 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0119 - acc: 1.0000\n",
      "\n",
      "episode: 50/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1384 - acc: 0.7272\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3119 - acc: 0.9187\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1897 - acc: 0.9527\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1400 - acc: 0.9688\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1250 - acc: 0.9660\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0975 - acc: 0.9794\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0894 - acc: 0.9833\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1313 - acc: 0.9710\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0672 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0598 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0532 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0483 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0455 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0415 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0386 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0361 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0344 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0306 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0286 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0271 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0256 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0241 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0228 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0217 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0269 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0199 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0194 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0184 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0174 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0173 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2259 - acc: 0.6860\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3066 - acc: 0.9215\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2057 - acc: 0.9471\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2782 - acc: 0.9282\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1171 - acc: 0.9755\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1155 - acc: 0.9699\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0866 - acc: 0.9800\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0744 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0619 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1305 - acc: 0.9671\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0573 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0463 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0426 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0373 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0344 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0308 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0285 - acc: 0.9983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0277 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0252 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0233 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0222 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0224 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0195 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0197 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0167 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0169 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0154 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0188 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0142 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0132 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 0.9773 - acc: 0.7116\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2974 - acc: 0.9293\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1990 - acc: 0.9549\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1410 - acc: 0.9683\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1112 - acc: 0.9766\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1177 - acc: 0.9694\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0918 - acc: 0.9766\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0681 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0693 - acc: 0.9855\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0546 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0495 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0447 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0384 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0394 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0321 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0296 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0290 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0321 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0253 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0237 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0255 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0204 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0187 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0180 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0173 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0159 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0157 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0149 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0139 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0135 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1671 - acc: 0.6843\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2878 - acc: 0.9354\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1844 - acc: 0.9582\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3955 - acc: 0.9182\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1185 - acc: 0.9705\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0930 - acc: 0.9794\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0797 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0686 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0581 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0509 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0479 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0425 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0447 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0483 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0326 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0307 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0282 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0257 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0241 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0226 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0209 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0204 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0193 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0184 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0173 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0165 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0151 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0147 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0142 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0133 - acc: 1.0000\n",
      "\n",
      "episode: 54/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1677 - acc: 0.6826\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3102 - acc: 0.9237\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2037 - acc: 0.9510\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1758 - acc: 0.9594\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1849 - acc: 0.9538\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1005 - acc: 0.9794\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0789 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0707 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0613 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0549 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0496 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0465 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0424 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0368 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0364 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0322 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0306 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0278 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0258 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0257 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0221 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0229 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0203 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0198 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0190 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0170 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0166 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0158 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0149 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0140 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2187 - acc: 0.6709\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3176 - acc: 0.9170\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2157 - acc: 0.9449\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1607 - acc: 0.9588\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1439 - acc: 0.9688\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1189 - acc: 0.9716\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3840 - acc: 0.9298\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0919 - acc: 0.9783\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0802 - acc: 0.9777\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0659 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0582 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0517 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0467 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0416 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0385 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0354 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0332 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0321 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0279 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0261 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0246 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0223 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0288 - acc: 0.9955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0199 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0190 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0173 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0173 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0163 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0162 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0142 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2544 - acc: 0.7055\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2983 - acc: 0.9243\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1970 - acc: 0.9516\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1517 - acc: 0.9638\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1483 - acc: 0.9616\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1029 - acc: 0.9766\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0931 - acc: 0.9788\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0724 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0692 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0576 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0644 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0501 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0441 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0402 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0413 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0403 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0321 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0301 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0274 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0256 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0238 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0228 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0222 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0240 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0196 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0183 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0170 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0170 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0162 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0151 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0497 - acc: 0.7266\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2690 - acc: 0.9332\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1633 - acc: 0.9621\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1397 - acc: 0.9638\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1021 - acc: 0.9766\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0849 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0719 - acc: 0.9850\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0600 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0541 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0488 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0432 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0385 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0656 - acc: 0.9805\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0318 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0293 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0279 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0248 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0231 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0219 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0217 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0191 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0177 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0169 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0186 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0150 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0146 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0155 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0132 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0127 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0120 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1154 - acc: 0.6921\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2695 - acc: 0.9376\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1823 - acc: 0.9577\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1693 - acc: 0.9627\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1081 - acc: 0.9777\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0916 - acc: 0.9822\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0783 - acc: 0.9850\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0678 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0632 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0551 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0484 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0438 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0425 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0369 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3283 - acc: 0.9482\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0456 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0357 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0298 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0278 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0254 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0228 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0226 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0209 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0188 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0174 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0170 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0228 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0153 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0162 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0141 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2605 - acc: 0.6915\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2930 - acc: 0.9287\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2100 - acc: 0.9521\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1372 - acc: 0.9705\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1093 - acc: 0.9761\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1094 - acc: 0.9738\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1414 - acc: 0.9688\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0678 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0583 - acc: 0.9900\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0508 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0462 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0415 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0362 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0351 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0311 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0667 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0266 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0239 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0231 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0208 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0198 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0183 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0178 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0162 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0160 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0153 - acc: 1.0000\n",
      "\n",
      "episode: 60/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0987 - acc: 0.7094\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2937 - acc: 0.9243\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2983 - acc: 0.9204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1291 - acc: 0.9694\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1018 - acc: 0.9783\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0901 - acc: 0.9811\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0697 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0670 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0542 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0480 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0425 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0402 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0376 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0324 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0304 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0328 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0266 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0254 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0236 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0240 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0206 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0191 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0183 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0174 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0171 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0154 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0148 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0147 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0132 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0125 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2208 - acc: 0.6949\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3401 - acc: 0.9148\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2052 - acc: 0.9538\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1401 - acc: 0.9694\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1174 - acc: 0.9800\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0984 - acc: 0.9822\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1069 - acc: 0.9816\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0701 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0623 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0593 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0496 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0440 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0434 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0365 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0333 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0310 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0291 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0287 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0254 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0247 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0227 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0214 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0200 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0193 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0184 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0172 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0158 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0156 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0149 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0157 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.3469 - acc: 0.6720\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3254 - acc: 0.9187\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1878 - acc: 0.9588\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1496 - acc: 0.9616\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1188 - acc: 0.9733\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1041 - acc: 0.9761\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0899 - acc: 0.9772\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0730 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0685 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0562 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0545 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0591 - acc: 0.9900\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0420 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0382 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0339 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0328 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0393 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0288 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0265 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0247 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0240 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0220 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0209 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0251 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0192 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0172 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0164 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0154 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0152 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0156 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.3520 - acc: 0.6815\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3904 - acc: 0.8987\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2096 - acc: 0.9399\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1344 - acc: 0.9688\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1106 - acc: 0.9761\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0884 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0788 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0644 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0569 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0518 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0559 - acc: 0.9900\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0541 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0394 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0357 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0328 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0305 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0281 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0260 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0275 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0229 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0210 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0232 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0189 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0183 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0169 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0171 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0162 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0146 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0139 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0137 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2027 - acc: 0.6748\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2829 - acc: 0.9332\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1790 - acc: 0.9599\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1359 - acc: 0.9694\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1075 - acc: 0.9744\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0897 - acc: 0.9827\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0726 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0614 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0787 - acc: 0.9800\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0522 - acc: 0.9916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0437 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0407 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0370 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0322 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0307 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0269 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0255 - acc: 0.9967\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0224 - acc: 0.9989\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0217 - acc: 0.9989\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0212 - acc: 0.9989\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0208 - acc: 0.9989\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0194 - acc: 0.9989\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0189 - acc: 0.9983\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0186 - acc: 0.9989\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0180 - acc: 0.9989\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0176 - acc: 0.9994\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0169 - acc: 0.9994\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0164 - acc: 0.9994\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0159 - acc: 1.0000\n",
      "\n",
      "episode: 65/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2069 - acc: 0.6938\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3168 - acc: 0.9159\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2173 - acc: 0.9460\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1534 - acc: 0.9610\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1226 - acc: 0.9744\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1005 - acc: 0.9788\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0925 - acc: 0.9800\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0775 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0694 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0597 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0525 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0573 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0439 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0423 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0358 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0328 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0317 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0300 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0273 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0248 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0240 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0254 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0216 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0193 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0180 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0180 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0172 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0156 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0149 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0142 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1331 - acc: 0.7071\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3356 - acc: 0.9042\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1771 - acc: 0.9549\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1319 - acc: 0.9738\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1728 - acc: 0.9616\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0886 - acc: 0.9833\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1005 - acc: 0.9772\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0649 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0610 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0540 - acc: 0.9900\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0756 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0431 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0420 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0348 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0321 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0298 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0302 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0259 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0245 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0232 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0203 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0195 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0183 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0180 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0169 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0160 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0151 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0143 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0140 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0131 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.4772 - acc: 0.6581\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3690 - acc: 0.9098\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2066 - acc: 0.9510\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1925 - acc: 0.9471\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1208 - acc: 0.9727\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1009 - acc: 0.9777\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0882 - acc: 0.9811\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2727 - acc: 0.9438\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0759 - acc: 0.9850\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0618 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0571 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0573 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0442 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0408 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0366 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1317 - acc: 0.9694\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0338 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0299 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0311 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0266 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0246 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0224 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0215 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0196 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0191 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0182 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0176 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0163 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0155 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0148 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1636 - acc: 0.7010\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2866 - acc: 0.9237\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1632 - acc: 0.9644\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1213 - acc: 0.9716\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1073 - acc: 0.9710\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0793 - acc: 0.9855\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0670 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0653 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0561 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0457 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2174 - acc: 0.9621\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0434 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0358 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0333 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0293 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0283 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0248 - acc: 0.9978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0236 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0211 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0194 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0196 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0179 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0163 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0153 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0147 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0140 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0131 - acc: 1.0000\n",
      "\n",
      "episode: 69/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.3230 - acc: 0.6676\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3175 - acc: 0.9226\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1941 - acc: 0.9605\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1434 - acc: 0.9694\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1143 - acc: 0.9783\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0968 - acc: 0.9822\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1189 - acc: 0.9677\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0891 - acc: 0.9794\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1270 - acc: 0.9677\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0650 - acc: 0.9866\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0679 - acc: 0.9844\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0354 - acc: 0.9955\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0349 - acc: 0.9944\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0258 - acc: 0.9972\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0219 - acc: 0.9983\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0191 - acc: 0.9983\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0195 - acc: 0.9967\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0168 - acc: 0.9983\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0152 - acc: 0.9983\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0139 - acc: 0.9983\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0119 - acc: 0.9994\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0113 - acc: 0.9994\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0105 - acc: 1.0000\n",
      "\n",
      "episode: 70/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1877 - acc: 0.6932\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3228 - acc: 0.9109\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3698 - acc: 0.9154\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1402 - acc: 0.9638\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1109 - acc: 0.9761\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0990 - acc: 0.9755\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0764 - acc: 0.9850\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0719 - acc: 0.9883\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0679 - acc: 0.9872\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0639 - acc: 0.9872\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0585 - acc: 0.9900\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0562 - acc: 0.9916\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0551 - acc: 0.9916\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0505 - acc: 0.9916\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0526 - acc: 0.9905\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0637 - acc: 0.9872\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0429 - acc: 0.9928\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0418 - acc: 0.9939\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0396 - acc: 0.9944\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0374 - acc: 0.9939\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0361 - acc: 0.9950\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0345 - acc: 0.9955\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0349 - acc: 0.9955\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0366 - acc: 0.9944\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0311 - acc: 0.9961\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0296 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0407 - acc: 0.9939\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0274 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0267 - acc: 0.9967\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0261 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.3958 - acc: 0.6643\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3148 - acc: 0.9204\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1892 - acc: 0.9588\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1499 - acc: 0.9649\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1101 - acc: 0.9766\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0925 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0787 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0686 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0608 - acc: 0.9900\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0750 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0508 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0428 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0412 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0369 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0340 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0307 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0461 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0279 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0269 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0248 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0215 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0206 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0196 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0194 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0172 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0166 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0159 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0148 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0153 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0138 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.4849 - acc: 0.6459\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3210 - acc: 0.9298\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3408 - acc: 0.9109\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1825 - acc: 0.9599\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1331 - acc: 0.9699\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1016 - acc: 0.9800\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0845 - acc: 0.9850\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0751 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0640 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0585 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0517 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0490 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0437 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0406 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0383 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0396 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0321 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0318 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0278 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0275 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0240 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0225 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0213 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0200 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0187 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0180 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0193 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0164 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0159 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0147 - acc: 1.0000\n",
      "\n",
      "episode: 73/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0652 - acc: 0.6765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3633 - acc: 0.8998\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2362 - acc: 0.9415\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1452 - acc: 0.9710\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1156 - acc: 0.9761\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0931 - acc: 0.9794\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0813 - acc: 0.9855\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0727 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1194 - acc: 0.9644\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0555 - acc: 0.9900\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0554 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0432 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0408 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0364 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0367 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0301 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0287 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0269 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0263 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0225 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0216 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0208 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0193 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0178 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0176 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0163 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0173 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0150 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0137 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0130 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1905 - acc: 0.6793\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3092 - acc: 0.9254\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1930 - acc: 0.9549\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1437 - acc: 0.9710\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1727 - acc: 0.9594\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0987 - acc: 0.9794\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1018 - acc: 0.9788\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0727 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0622 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0557 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0536 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0453 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0451 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0381 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0355 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0338 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0311 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0281 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0267 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0251 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0237 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0230 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0215 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0203 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0188 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0183 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0173 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0161 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0155 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0142 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1334 - acc: 0.6576\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3383 - acc: 0.9154\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2583 - acc: 0.9293\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1537 - acc: 0.9660\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1215 - acc: 0.9722\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1134 - acc: 0.9738\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0901 - acc: 0.9805\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0793 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0907 - acc: 0.9783\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0634 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0556 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0490 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0507 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0516 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0378 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0380 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0341 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0349 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0284 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0263 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0246 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0247 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0227 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0292 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0191 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0181 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0182 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0162 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0156 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0143 - acc: 1.0000\n",
      "\n",
      "episode: 76/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.4155 - acc: 0.6743\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3388 - acc: 0.9120\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2444 - acc: 0.9354\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1542 - acc: 0.9627\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1287 - acc: 0.9649\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1077 - acc: 0.9744\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1551 - acc: 0.9638\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0784 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0702 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0597 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0545 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0487 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0450 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0389 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0378 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0329 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0308 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0289 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0271 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0260 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0240 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0223 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0264 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0214 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0188 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0182 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0206 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0169 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0154 - acc: 1.0000\n",
      "\n",
      "episode: 77/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2034 - acc: 0.6553\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3417 - acc: 0.9159\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3085 - acc: 0.9226\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1389 - acc: 0.9699\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1111 - acc: 0.9794\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1082 - acc: 0.9794\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0804 - acc: 0.9833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0687 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0603 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0583 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0484 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0448 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0409 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0380 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0339 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0318 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0298 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0274 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0257 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0264 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0227 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0216 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0198 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0183 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0227 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0169 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0159 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0175 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0159 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0136 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2979 - acc: 0.7077\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2857 - acc: 0.9243\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1880 - acc: 0.9516\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1442 - acc: 0.9644\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1304 - acc: 0.9677\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0894 - acc: 0.9805\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0766 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0679 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0611 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0543 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0480 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0445 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0424 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0390 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0342 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0302 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0287 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0264 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0249 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0244 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0218 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0211 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0201 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0185 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0168 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0160 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0154 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0147 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0140 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0143 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0995 - acc: 0.6954\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3225 - acc: 0.9165\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2150 - acc: 0.9438\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1387 - acc: 0.9677\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1166 - acc: 0.9699\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0967 - acc: 0.9788\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1258 - acc: 0.9688\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0869 - acc: 0.9738\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0560 - acc: 0.9889\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0502 - acc: 0.9883\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0422 - acc: 0.9905\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0329 - acc: 0.9967\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0255 - acc: 0.9978\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0231 - acc: 0.9983\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0199 - acc: 0.9989\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0165 - acc: 0.9989\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0175 - acc: 0.9989\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0138 - acc: 1.0000\n",
      "\n",
      "episode: 80/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2644 - acc: 0.6548\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3534 - acc: 0.9020\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2913 - acc: 0.9298\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1460 - acc: 0.9727\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1226 - acc: 0.9749\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1109 - acc: 0.9772\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0858 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0770 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0646 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0586 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0514 - acc: 0.9939\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0451 - acc: 0.9950\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0415 - acc: 0.9950\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0406 - acc: 0.9955\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0388 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0375 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0357 - acc: 0.9967\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0347 - acc: 0.9967\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0332 - acc: 0.9967\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0333 - acc: 0.9967\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0312 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0302 - acc: 0.9983\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0286 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0276 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0270 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0271 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0261 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0245 - acc: 0.9983\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0243 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0240 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0935 - acc: 0.7004\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3001 - acc: 0.9254\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2919 - acc: 0.9215\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1431 - acc: 0.9699\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1369 - acc: 0.9699\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0979 - acc: 0.9805\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0857 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0773 - acc: 0.9827\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0651 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0705 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0523 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0486 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0452 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0395 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0370 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0329 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0325 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0278 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0270 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0243 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0232 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0227 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0207 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0192 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0188 - acc: 0.9983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0179 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0169 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0159 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0149 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0140 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0240 - acc: 0.7210\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2575 - acc: 0.9388\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1751 - acc: 0.9571\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2417 - acc: 0.9465\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1078 - acc: 0.9805\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1065 - acc: 0.9716\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0735 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0625 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0664 - acc: 0.9855\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1025 - acc: 0.9755\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0485 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0397 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0361 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0314 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0283 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0269 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0255 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0227 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0215 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0208 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0199 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0183 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0174 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0159 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0156 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0144 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0140 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0135 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0129 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0128 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1258 - acc: 0.6759\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3249 - acc: 0.9204\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2442 - acc: 0.9449\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1762 - acc: 0.9538\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1977 - acc: 0.9549\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1041 - acc: 0.9783\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0595 - acc: 0.9894\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0490 - acc: 0.9922\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0386 - acc: 0.9939\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0366 - acc: 0.9944\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0352 - acc: 0.9922\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0242 - acc: 0.9978\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0222 - acc: 0.9978\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0205 - acc: 0.9978\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0171 - acc: 0.9989\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0160 - acc: 0.9983\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0137 - acc: 0.9989\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0143 - acc: 0.9989\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0112 - acc: 0.9994\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0133 - acc: 0.9989\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0100 - acc: 0.9994\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0096 - acc: 1.0000\n",
      "\n",
      "episode: 84/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.4952 - acc: 0.6592\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3657 - acc: 0.8987\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2248 - acc: 0.9438\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1657 - acc: 0.9605\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1247 - acc: 0.9699\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1059 - acc: 0.9738\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2797 - acc: 0.9393\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0819 - acc: 0.9850\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0715 - acc: 0.9855\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0622 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0551 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0530 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0469 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0448 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0399 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0365 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0337 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0314 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0288 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0271 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0272 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0238 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0242 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0217 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0198 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0194 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0226 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0183 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0167 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0162 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2848 - acc: 0.6771\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2972 - acc: 0.9304\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2317 - acc: 0.9415\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1446 - acc: 0.9677\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1139 - acc: 0.9761\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1028 - acc: 0.9777\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0822 - acc: 0.9855\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0724 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0648 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0557 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0512 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0470 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0427 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0385 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0354 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0325 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0309 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0292 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0257 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0246 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0234 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0217 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0212 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0192 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0190 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0176 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0168 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0154 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0153 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0145 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.2481 - acc: 0.6960\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3261 - acc: 0.9243\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2269 - acc: 0.9427\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1673 - acc: 0.9594\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2197 - acc: 0.9432\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1184 - acc: 0.9738\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0841 - acc: 0.9855\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0729 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0712 - acc: 0.9883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0591 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0531 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0477 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0469 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0397 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0369 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0422 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0339 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0280 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0292 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0269 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0247 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0232 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0216 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0207 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0192 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0194 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0175 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0179 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0168 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0175 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1745 - acc: 0.7043\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3090 - acc: 0.9187\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1905 - acc: 0.9538\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1328 - acc: 0.9733\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1303 - acc: 0.9705\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0983 - acc: 0.9788\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0780 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0677 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0604 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2072 - acc: 0.9566\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0513 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0461 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0416 - acc: 0.9944\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0356 - acc: 0.9950\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0340 - acc: 0.9955\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0325 - acc: 0.9961\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0311 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0297 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0290 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0279 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0267 - acc: 0.9972\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0263 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0251 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0242 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0240 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0228 - acc: 0.9983\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0222 - acc: 0.9978\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0218 - acc: 0.9983\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0206 - acc: 0.9989\n",
      "learning rate: 0.005\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0208 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0172 - acc: 0.7021\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3274 - acc: 0.9159\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1996 - acc: 0.9532\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1406 - acc: 0.9694\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1102 - acc: 0.9800\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0869 - acc: 0.9855\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0851 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0673 - acc: 0.9883\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1408 - acc: 0.9633\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0528 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0500 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0410 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0366 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0340 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0307 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0291 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0286 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0245 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0235 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0221 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0211 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0196 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0189 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0182 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0165 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0157 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0167 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0146 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0133 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0134 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1666 - acc: 0.6932\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2761 - acc: 0.9310\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1799 - acc: 0.9543\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1328 - acc: 0.9660\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3012 - acc: 0.9310\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0905 - acc: 0.9788\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0742 - acc: 0.9855\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0675 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0568 - acc: 0.9900\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0507 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0456 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0400 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0527 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0350 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0338 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0290 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0270 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0263 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0234 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0236 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0204 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0200 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0188 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0172 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0164 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0162 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0147 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0142 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0138 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0127 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.4172 - acc: 0.6459\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3210 - acc: 0.9254\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2082 - acc: 0.9560\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1543 - acc: 0.9660\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1213 - acc: 0.9738\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1089 - acc: 0.9727\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0900 - acc: 0.9833\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1602 - acc: 0.9638\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0751 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0616 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0585 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0495 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0469 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0423 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0389 - acc: 0.9955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0342 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0325 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0302 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0287 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0260 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0263 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0230 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0217 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0206 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0200 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0183 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0175 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0167 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0162 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0146 - acc: 1.0000\n",
      "\n",
      "episode: 91/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1413 - acc: 0.7021\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.5211 - acc: 0.8786\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1833 - acc: 0.9560\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1513 - acc: 0.9655\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1096 - acc: 0.9749\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0995 - acc: 0.9772\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0787 - acc: 0.9850\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0696 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0563 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0545 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0620 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0438 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0365 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0340 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0303 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0281 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0257 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0242 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0225 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0214 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0213 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0193 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0172 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0311 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0161 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0148 - acc: 1.0000\n",
      "\n",
      "episode: 92/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1061 - acc: 0.6720\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3280 - acc: 0.9148\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2012 - acc: 0.9504\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1527 - acc: 0.9660\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1183 - acc: 0.9749\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0992 - acc: 0.9811\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0820 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0740 - acc: 0.9855\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0596 - acc: 0.9900\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0553 - acc: 0.9905\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0498 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0443 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0425 - acc: 0.9955\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0489 - acc: 0.9933\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0362 - acc: 0.9950\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0336 - acc: 0.9961\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0282 - acc: 0.9944\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0218 - acc: 0.9972\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0218 - acc: 0.9978\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0191 - acc: 0.9978\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0179 - acc: 0.9978\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0161 - acc: 0.9983\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0130 - acc: 0.9994\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0124 - acc: 0.9989\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0105 - acc: 1.0000\n",
      "\n",
      "episode: 93/100, score: 1.0, e: 0.01\n",
      "\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0860 - acc: 0.7110\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3044 - acc: 0.9232\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3995 - acc: 0.9092\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1423 - acc: 0.9694\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1142 - acc: 0.9749\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0964 - acc: 0.9766\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0829 - acc: 0.9822\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0735 - acc: 0.9844\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0681 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0591 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0517 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0472 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0439 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0402 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0369 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0385 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0393 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0294 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0277 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0267 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0243 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0232 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0217 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0203 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0201 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0186 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0177 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0167 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0160 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0150 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1574 - acc: 0.6687\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3893 - acc: 0.8964\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2525 - acc: 0.9354\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1454 - acc: 0.9677\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1165 - acc: 0.9794\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0990 - acc: 0.9800\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0833 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0730 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0669 - acc: 0.9872\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0578 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0516 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0434 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0412 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0390 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0337 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0318 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0302 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0275 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0253 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0232 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0557 - acc: 0.9855\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0245 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0198 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0187 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0177 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0167 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0154 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0144 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0149 - acc: 0.9994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0132 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1596 - acc: 0.6698\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3187 - acc: 0.9131\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2108 - acc: 0.9516\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1527 - acc: 0.9605\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1159 - acc: 0.9744\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1025 - acc: 0.9755\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0821 - acc: 0.9833\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0716 - acc: 0.9855\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0648 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0626 - acc: 0.9889\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0501 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2104 - acc: 0.9549\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0450 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0401 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0354 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0544 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0317 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0363 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0282 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0235 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0244 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0208 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0202 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0193 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0175 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0174 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0161 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0149 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0140 - acc: 0.9989\n",
      "learning rate: 0.02\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0193 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.0855 - acc: 0.6876\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3149 - acc: 0.9243\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2032 - acc: 0.9477\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1545 - acc: 0.9660\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1219 - acc: 0.9755\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1016 - acc: 0.9800\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0877 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0743 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0649 - acc: 0.9900\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0597 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0523 - acc: 0.9922\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0471 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0427 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0395 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0515 - acc: 0.9911\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0337 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0328 - acc: 0.9955\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0282 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0276 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0257 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0248 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0227 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0215 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0203 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0194 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0183 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0176 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0196 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0165 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0146 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1275 - acc: 0.6782\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3259 - acc: 0.9148\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1904 - acc: 0.9465\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1464 - acc: 0.9627\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1061 - acc: 0.9805\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1152 - acc: 0.9722\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0817 - acc: 0.9839\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0727 - acc: 0.9855\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0591 - acc: 0.9900\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0514 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0460 - acc: 0.9933\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0431 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0559 - acc: 0.9878\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0364 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0320 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0288 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0265 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0326 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0241 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0227 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0216 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0195 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0176 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0168 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0164 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0157 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0148 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0161 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0135 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0130 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.1558 - acc: 0.6871\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3975 - acc: 0.8925\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1868 - acc: 0.9594\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1349 - acc: 0.9705\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1118 - acc: 0.9783\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0928 - acc: 0.9805\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1345 - acc: 0.9699\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0702 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0890 - acc: 0.9788\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0551 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0475 - acc: 0.9928\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0417 - acc: 0.9950\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0396 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0354 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0355 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0302 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0282 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0260 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0252 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0232 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0220 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0200 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0192 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0171 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0183 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0157 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0158 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0151 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0141 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0137 - acc: 0.9989\n"
     ]
    }
   ],
   "source": [
    "EPISODES = 100\n",
    "IMPROVE_COEFF = 0.0\n",
    "MAX_EPOCHS = 30\n",
    "NUM_EPOCHS = 1\n",
    "LR = 0.01\n",
    "\n",
    "state_size = 5\n",
    "action_size = 3\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "done = False\n",
    "batch_size = 32\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    \n",
    "    state = [np.inf, 0.0, lr, np.inf, 0.0]\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    model, loss_history, lrate = reset_env(LR)\n",
    "    \n",
    "    for time in range(MAX_EPOCHS):\n",
    "        \n",
    "        # Agent acts, env updates\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done = step_env(action, model, loss_history, lrate, IMPROVE_COEFF, NUM_EPOCHS)\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        \n",
    "        # Agent remembers\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            print(\"\\nepisode: {}/{}, score: {}, e: {:.2}\\n\"\n",
    "                  .format(e, EPISODES, loss_history.acc[-1], agent.epsilon))\n",
    "            break\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 1s - loss: 1.3629 - acc: 0.6682\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.3310 - acc: 0.9131\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2711 - acc: 0.9287\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.2029 - acc: 0.9488\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.1125 - acc: 0.9755\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0924 - acc: 0.9816\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0844 - acc: 0.9816\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0696 - acc: 0.9866\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0649 - acc: 0.9894\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0515 - acc: 0.9916\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0453 - acc: 0.9939\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0429 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0396 - acc: 0.9944\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0373 - acc: 0.9961\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0321 - acc: 0.9967\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0308 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0295 - acc: 0.9978\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0265 - acc: 0.9972\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0232 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0217 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0212 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0663 - acc: 0.9861\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0208 - acc: 0.9983\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0188 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0171 - acc: 0.9994\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0160 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0159 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0140 - acc: 0.9989\n",
      "learning rate: 0.01\n",
      "\n",
      "1796/1796 - 0s - loss: 0.0138 - acc: 1.0000\n",
      "\n",
      "episode: 99/100, score: 1.0, e: 0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = [np.inf, 0.0, lr, np.inf, 0.0]\n",
    "state = np.reshape(state, [1, state_size])\n",
    "model, loss_history, lrate = reset_env(LR)\n",
    "\n",
    "for time in range(30):\n",
    "\n",
    "    # Agent acts, env updates\n",
    "    action = agent.act(state)\n",
    "    next_state, reward, done = step_env(action, model, loss_history, lrate, IMPROVE_COEFF, num_epochs=1)\n",
    "    next_state = np.reshape(next_state, [1, state_size])\n",
    "    state = next_state\n",
    "\n",
    "    if done:\n",
    "        print(\"\\nepisode: {}/{}, score: {}, e: {:.2}\\n\"\n",
    "              .format(e, EPISODES, loss_history.acc[-1], agent.epsilon))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0,
          0.6681514382362366,
          0.9131402969360352,
          0.9287304878234863,
          0.948775053024292,
          0.9755011200904846,
          0.9816258549690247,
          0.9816258549690247,
          0.9866369962692261,
          0.9894209504127502,
          0.9916480779647827,
          0.99387526512146,
          0.9944320917129517,
          0.9944320917129517,
          0.9961024522781372,
          0.9966592192649841,
          0.9972160458564758,
          0.9977728128433228,
          0.9972160458564758,
          0.9988864064216614,
          0.9988864064216614,
          0.9988864064216614,
          0.9860801696777344,
          0.9983296394348145,
          0.9988864064216614,
          0.9994432330131531,
          0.9988864064216614,
          0.9988864064216614,
          0.9988864064216614,
          1
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"b8cf7f3d-eeb6-459d-91ce-6e418aceec10\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"b8cf7f3d-eeb6-459d-91ce-6e418aceec10\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'b8cf7f3d-eeb6-459d-91ce-6e418aceec10',\n",
       "                        [{\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.0, 0.6681514382362366, 0.9131402969360352, 0.9287304878234863, 0.948775053024292, 0.9755011200904846, 0.9816258549690247, 0.9816258549690247, 0.9866369962692261, 0.9894209504127502, 0.9916480779647827, 0.99387526512146, 0.9944320917129517, 0.9944320917129517, 0.9961024522781372, 0.9966592192649841, 0.9972160458564758, 0.9977728128433228, 0.9972160458564758, 0.9988864064216614, 0.9988864064216614, 0.9988864064216614, 0.9860801696777344, 0.9983296394348145, 0.9988864064216614, 0.9994432330131531, 0.9988864064216614, 0.9988864064216614, 0.9988864064216614, 1.0]}],\n",
       "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('b8cf7f3d-eeb6-459d-91ce-6e418aceec10');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01,
          0.01
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"874c1c9e-4234-4290-acba-f724236949b0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"874c1c9e-4234-4290-acba-f724236949b0\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '874c1c9e-4234-4290-acba-f724236949b0',\n",
       "                        [{\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]}],\n",
       "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('874c1c9e-4234-4290-acba-f724236949b0');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "fig = go.Figure([go.Scatter(x=pd.Series(range(len(loss_history.acc))), y=pd.Series(loss_history.acc))])\n",
    "fig.show()\n",
    "fig = go.Figure([go.Scatter(x=pd.Series(range(len(loss_history.lr))), y=pd.Series(loss_history.lr))])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent():\n",
    "    \n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma *\n",
    "                          np.amax(self.model.predict(next_state)[0]))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/1000, score: 16, e: 1.0\n",
      "episode: 1/1000, score: 11, e: 1.0\n",
      "episode: 2/1000, score: 16, e: 0.94\n",
      "episode: 3/1000, score: 10, e: 0.89\n",
      "episode: 4/1000, score: 55, e: 0.68\n",
      "episode: 5/1000, score: 10, e: 0.64\n",
      "episode: 6/1000, score: 19, e: 0.58\n",
      "episode: 7/1000, score: 16, e: 0.54\n",
      "episode: 8/1000, score: 11, e: 0.51\n",
      "episode: 9/1000, score: 12, e: 0.48\n",
      "episode: 10/1000, score: 10, e: 0.46\n",
      "episode: 11/1000, score: 12, e: 0.43\n",
      "episode: 12/1000, score: 9, e: 0.41\n",
      "episode: 13/1000, score: 10, e: 0.39\n",
      "episode: 14/1000, score: 8, e: 0.38\n",
      "episode: 15/1000, score: 10, e: 0.36\n",
      "episode: 16/1000, score: 8, e: 0.34\n",
      "episode: 17/1000, score: 9, e: 0.33\n",
      "episode: 18/1000, score: 8, e: 0.32\n",
      "episode: 19/1000, score: 144, e: 0.15\n",
      "episode: 20/1000, score: 125, e: 0.082\n",
      "episode: 21/1000, score: 57, e: 0.062\n",
      "episode: 22/1000, score: 43, e: 0.05\n",
      "episode: 23/1000, score: 17, e: 0.046\n",
      "episode: 24/1000, score: 50, e: 0.035\n",
      "episode: 25/1000, score: 23, e: 0.032\n",
      "episode: 26/1000, score: 20, e: 0.029\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-3934a42c125b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-6e35d6407a53>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 target = (reward + self.gamma *\n\u001b[0;32m---> 39\u001b[0;31m                           np.amax(self.model.predict(next_state)[0]))\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mtarget_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mtarget_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1076\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m           callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.virtualenvs/sandbox/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPISODES = 1000\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "# agent.load(\"./save/cartpole-dqn.h5\")\n",
    "done = False\n",
    "batch_size = 32\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    for time in range(500):\n",
    "        env.render()\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        reward = reward if not done else -10\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        \n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
    "                  .format(e, EPISODES, time, agent.epsilon))\n",
    "            break\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "sandbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
